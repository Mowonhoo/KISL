{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58d09fb-677f-4e51-9d00-473bc880f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import os,re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "plt.rcParams['axes.unicode_minus'] = False#使用上标小标小一字号\n",
    "plt.rcParams['font.sans-serif']=['Times New Roman']\n",
    "#设置全局字体，可选择需要的字体替换掉‘Times New Roman’\n",
    "#使用黑体'SimHei'作为全局字体，可以显示中文\n",
    "#plt.rcParams['font.sans-serif']=['SimHei']\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score, calinski_harabasz_score # CH 指标，DBI \n",
    "from sklearn.metrics import silhouette_samples, silhouette_score # 轮廓系数\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.spatial.distance import cdist#cdist(XA, XB, 'correlation')\n",
    "from dcor import distance_correlation as dcorr\n",
    "from scipy.stats import pearsonr\n",
    "#    1）输入：x为特征，y为目标变量.\n",
    "#    2）输出：r： 相关系数 [-1，1]之间，p-value: p值。\n",
    "#         注： p值越小，表示相关系数越显著，一般p值在500个样本以上时有较高的可靠性。\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from matplotlib.axes._axes import _log as matplotlib_axes_logger\n",
    "matplotlib_axes_logger.setLevel('ERROR')#日志只显示error级别的错误\n",
    "\n",
    "from pckmeans import PCKMeans\n",
    "from mpckmeans import MPCKMeans\n",
    "\n",
    "##my\n",
    "from labels2color import Labels2Color\n",
    "#from topological_overlap_measure import TOMsimilarity\n",
    "from topological_overlap_measure import *\n",
    "#from soothsayer.networks import topological_overlap_measure\n",
    "\n",
    "from visualization import *\n",
    "from my_functions import *\n",
    "\n",
    "# cancer_names = [\"BLCA\", \"BRCA\", \"COAD\", \"KIRC\", \"LUAD\", \"LUSC\", \"STAD\",  \"PAAD\"]#\n",
    "mldir = \"E:/Project/Project001 WGCNA/main/step-6-FactorAnalyzer/outdir\"\n",
    "data_indir = \"E:/Project/Project001 WGCNA/main/step-3-FeatureSelection/outdir\"\n",
    "labelsdir = \"E:/Project/Project001 WGCNA/main/step-4-wgcna/outdir\"\n",
    "out_dir = \"E:/Project/Project001 WGCNA/main/step-7-clustering/semi_supervised Kmeans/outdir\"\n",
    "dcorr_dir = \"E:/Project/Project001 WGCNA/main/step-7-clustering/Calculate the correlation coefficient/outdir\"\n",
    "\n",
    "distance = \"dcorr\" #\"pearson\" #\n",
    "power = 20\n",
    "filename = 'BLCA.tcga_gtex.tpm.updown.feature_selection.csv'\n",
    "# filename = 'BLCA.tumor.tpm.updown.feature_selection.csv'\n",
    "prefix = filename.split('.')[0]\n",
    "\n",
    "mlDir = '/'.join([mldir, filename.split('.')[1]])\n",
    "labelsDir = '/'.join([labelsdir, filename.split('.')[1]])\n",
    "# outdir = os.path.join(outdir, filename.split('.'))\n",
    "outdir = '/'.join([out_dir, filename.split('.')[1], distance])\n",
    "dcorrDir = '/'.join([dcorr_dir, filename.split('.')[1]])\n",
    "\n",
    "if not os.path.exists(os.path.join(outdir, prefix)):\n",
    "    os.makedirs(os.path.join(outdir, prefix))\n",
    "    \n",
    "assess = dict(wgcna = dict(SI = 0, CH = 0, DBI = 0, module_density_max = 0)\n",
    "              , pckmeans = dict(SI = 0, CH = 0, DBI = 0, module_density_max = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf8ecf5-2677-4653-ad7f-368318e1064b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "### 构建GCN网络计算dissTOM矩阵 ###\n",
    "##########################################\n",
    "datExpr = pd.read_csv(os.path.join(data_indir, prefix, filename), sep=',', index_col=0)\n",
    "if distance == \"pearson\":\n",
    "    print(\"Input: datExpr.shape\", datExpr.shape)\n",
    "    print(\"NAN check for datExpr: \", datExpr.isnull().values.sum())\n",
    "    sim = datExpr.T.corr()#dcor## # 计算pearson相关系数，得到相似矩阵\n",
    "elif distance == \"snn\":\n",
    "    print(\"Input: datExpr.shape\", datExpr.shape)\n",
    "    print(\"NAN check for datExpr: \", datExpr.isnull().values.sum())\n",
    "    sim = snn_sim_matrix(datExpr, k=5)\n",
    "elif distance == \"dcorr\":\n",
    "    sim = pd.read_csv(os.path.join(dcorrDir, prefix, filename.rstrip('.csv')+\".dcorr.csv\"), sep=',')\n",
    "    sim.index = sim.columns\n",
    "else:\n",
    "    print(\"input parameter error：Undefined distance type.\")\n",
    "\n",
    "print(\"NAN check: \", sim.isnull().values.sum())\n",
    "#先删除全是空值的行和列\n",
    "if sim.isnull().values.ravel().sum():\n",
    "    sim.drop(sim.columns[sim.isnull().all(axis=1)].tolist(), inplace=True)#删除全是NAN的行\n",
    "    sim = sim[sim.columns[~sim.isnull().all(axis=0)].tolist()]#删除全是NAN的列\n",
    "    #再用0填充NAN\n",
    "    sim.fillna(0, inplace=True)#用0填补缺失值\n",
    "print(\"After processing NA: sim.shape\", sim.shape)\n",
    "sim.to_csv(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".sim.csv\"), index=False, sep=',')\n",
    "\n",
    "\n",
    "# 调用R script计算软阈值\n",
    "sft = pickSoftThreshold(sim, power=power, RsquaredCut = 0.75, prefix=prefix, outdir=outdir)\n",
    "print('powerEstimate:%s' % sft[\"powerEstimate\"])\n",
    "sft[\"fitIndices\"].to_csv(os.path.join(outdir, prefix, filename.rstrip('.csv')+\"sft_fitIndices.csv\"), index=False, sep=',')\n",
    "\n",
    "\n",
    "#Check scale free topology\n",
    "# Create an adjacency network； ^6 近似无标度化\n",
    "# here we define the adjacency matrix using soft thresholding with beta=6\n",
    "ADJ = abs(sim)**sft[\"powerEstimate\"] # 近似无标度化\n",
    "print(\"Input: ADJ\", \"Max: {}\".format(ADJ.values.ravel().max()), \"Min: {}\".format(ADJ.values.ravel().min()), sep=\"\\n\")\n",
    "print(\"NAN check: \", ADJ.isnull().values.sum())\n",
    "ADJ.to_csv(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".ADJ.csv\"), index=False, sep=',')\n",
    "\n",
    "#计算邻接性\n",
    "Connectivity = ADJ.values\n",
    "row, col = np.diag_indices_from(Connectivity)\n",
    "Connectivity[row, col] = 0\n",
    "Connectivity = pd.DataFrame(Connectivity, columns=ADJ.columns)\n",
    "Connectivity.to_csv(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".Connectivity.csv\"), index=False, sep=',')\n",
    "\n",
    "# Compute topological overlap\n",
    "#from topological_overlap_measure import TOMsimilarity\n",
    "from topological_overlap_measure import *\n",
    "#from soothsayer.networks import topological_overlap_measure\n",
    "TOM = TOMsimilarity(ADJ)#把邻接矩阵转换为拓扑重叠矩阵topological_overlap_measure\n",
    "dissTOM = 1 - TOM\n",
    "\n",
    "TOM.to_csv(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".TOM.csv\"), index=False, sep=',')\n",
    "dissTOM.to_csv(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".dissTOM.csv\"), index=False, sep=',')\n",
    "\n",
    "X = dissTOM.copy()\n",
    "\n",
    "\n",
    "try:\n",
    "    import umap.umap_ as umap\n",
    "    from sklearn.manifold import TSNE\n",
    "    X_Dim = umap.UMAP(n_components=3).fit_transform(datExpr)\n",
    "    # 使用TSNE进行降维处理\n",
    "    # X_Dim = TSNE(n_components=3, learning_rate=100, random_state=0).fit_transform(datExpr) #\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"datExpr dimension reduction failed.\\n\")\n",
    "    print(e)\n",
    "    print(\"==============================\\n\")\n",
    "    X_Dim = TSNE(n_components=3, learning_rate=100, random_state=0).fit_transform(datExpr)\n",
    "    # X_Dim = umap.UMAP(n_components=3).fit_transform(datExpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53b8b36-bc1f-4fe2-a475-782048dc9862",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "### 可视化WGCNA聚类结果作为参考 ###\n",
    "##########################################\n",
    "print(\"WGCNA==========>\")\n",
    "method = 'WGCNA'\n",
    "wgcna_y_pred = pd.read_csv(os.path.join(labelsDir, prefix, prefix+\".wgcna.result.csv\"), index_col=False)\n",
    "wgcna_y_pred.index = wgcna_y_pred[\"gene\"].values\n",
    "wgcna_y_pred = wgcna_y_pred.loc[X.index]\n",
    "wgcna_labels = wgcna_y_pred[\"dynamicMods\"].values\n",
    "#print(\"value_counts:\\n\", pd.DataFrame(pd.value_counts(wgcna_labels)).T)\n",
    "labels_counts = pd.DataFrame(pd.value_counts(wgcna_labels, sort=False, ascending=False, normalize=False))\n",
    "labels_counts.insert(0, \"clusters\", labels_counts.index)\n",
    "labels_counts.columns = [\"clusters\", \"counts\"]\n",
    "labels_counts.to_csv(os.path.join(outdir, prefix, filename.rstrip('.csv')+\".%s_clustering.labels_counts.csv\" % method), index=False)\n",
    "pd.DataFrame(np.array([X.index, wgcna_labels]).T\n",
    "             , columns=[\"gene\", \"labels\"]\n",
    "            ).to_csv(os.path.join(outdir, prefix, filename.rstrip('.csv')+\".%s_clustering.cluster_labels.csv\" % method), index=False)#, header=None\n",
    "\n",
    "unique_labels = np.unique(wgcna_labels)\n",
    "##分类个数：lables中包含-1，表示噪声点\n",
    "n_clusters_ =len(np.unique(wgcna_labels)) - (1 if -1 in wgcna_labels else 0) \n",
    "WGCNA_K = n_clusters_\n",
    "\n",
    "SI = silhouette_score(X, wgcna_labels)\n",
    "CH = calinski_harabasz_score(X, wgcna_labels)\n",
    "DBI = davies_bouldin_score(X, wgcna_labels)\n",
    "sample_silhouette_values = silhouette_samples(X, wgcna_labels)\n",
    "\n",
    "assess['wgcna'][\"SI\"] = SI\n",
    "assess['wgcna'][\"CH\"] = CH\n",
    "assess['wgcna'][\"DBI\"] = DBI\n",
    "print(\"For n_clusters =\", n_clusters_,\n",
    "        \"\\nThe average silhouette_score is :\", SI)\n",
    "print(\"Calinski-Harabasz Score\",  CH,\n",
    "         \"\\nDavies Bouldin score is :\", DBI)\n",
    "\n",
    "colors = Labels2Color(X, wgcna_labels)['colorcode']\n",
    "SilhouetteAnalysis(X_Dim=X_Dim\n",
    "                   , labels=wgcna_labels\n",
    "                   , SI=SI\n",
    "                   , sample_silhouette_values=sample_silhouette_values\n",
    "                   , dirPrefix=os.path.join(outdir, prefix, filename.rstrip('.csv')+\".Silhouette analysis for WGCNA clustering on %s data\" % prefix)\n",
    "                   , suptitle=\"Silhouette analysis for WGCNA clustering on %s data with n_clusters = %d\" % (prefix, WGCNA_K)\n",
    "                   , colors=colors\n",
    "                   , D3=False\n",
    "                   , showplot=True\n",
    "                  )\n",
    "\n",
    "###画wgcna的基因数量图、模块平均连通性图和模块密度图###\n",
    "\n",
    "#每个模块的基因数条形图\n",
    "bar(x=labels_counts.loc[:, \"clusters\"], y=labels_counts.loc[:, \"counts\"]\n",
    "    , dirPrefix=os.path.join(outdir, prefix, filename.rstrip('.csv')+\".wgcna.Number of genes in the module\")\n",
    "    # , title=\" \"\n",
    "    , xlabel=\"Module\"\n",
    "    , ylabel=\"Number of genes\")\n",
    "genes_count = pd.DataFrame.from_dict({\"Module\":labels_counts.loc[:, \"clusters\"]\n",
    "                        , \"Number of genes\":labels_counts.loc[:, \"counts\"]\n",
    "                       })\n",
    "# genes_count.to_csv(os.path.join(outdir, prefix, filename.rstrip('.csv')+\".wgcna.Number of genes in the module.csv\"), index=False, sep=',')\n",
    "\n",
    "#模块内平均连通性\n",
    "values = []\n",
    "for k in np.sort(np.unique(wgcna_labels)):      \n",
    "    values.append(sum(Connectivity.loc[wgcna_labels==k, wgcna_labels==k].sum())/sum(wgcna_labels==k))\n",
    "bar(x=np.sort(np.unique(wgcna_labels)), y=values\n",
    "    , dirPrefix=os.path.join(outdir, prefix, filename.rstrip('.csv')+\".wgcna.Mean_Connectivity_of_module\")\n",
    "    # , title=\"Mean Connectivity of module\"\n",
    "    , xlabel=\"Module\"\n",
    "    , ylabel=\"Mean Connectivity\")\n",
    "Mean_Connectivity = pd.DataFrame.from_dict({'Module': np.sort(np.unique(wgcna_labels))\n",
    "                        , 'Mean Connectivity':values})\n",
    "# Mean_Connectivity.to_csv(os.path.join(outdir, prefix, filename.rstrip('.csv')+\".wgcna.Mean_Connectivity_of_module.csv\")\n",
    "#                                                    , index=False, sep=',')\n",
    "\n",
    "#模块密度\n",
    "values = []\n",
    "for k in np.sort(np.unique(wgcna_labels)):      \n",
    "    values.append(sum(Connectivity.loc[wgcna_labels==k, wgcna_labels==k].sum())/(sum(wgcna_labels==k)*(sum(wgcna_labels==k)-1)))\n",
    "assess['wgcna']['module_density_max'] = max(values)\n",
    "bar(x=np.sort(np.unique(wgcna_labels)), y=values\n",
    "    , dirPrefix=os.path.join(outdir, prefix, filename.rstrip('.csv')+\".wgcna.density_of_module\")\n",
    "    # , title=\" \"\n",
    "    , xlabel=\"Module\"\n",
    "    , ylabel=\"Density of module\")\n",
    "Density = pd.DataFrame.from_dict({'Module':np.sort(np.unique(wgcna_labels)), 'Density':values})\n",
    "# Density.to_csv(os.path.join(outdir, prefix, filename.rstrip('.csv')+\".wgcna.density_of_module.csv\"), index=False, sep=',')\n",
    "\n",
    "from functools import reduce\n",
    "summary = reduce(lambda left,right: pd.merge(left, right, on=['Module'], how='outer'), [genes_count, Mean_Connectivity, Density])\n",
    "summary.sort_values(by='Module', axis=0, ascending=True, inplace=True, ignore_index=True)\n",
    "summary.to_csv(os.path.join(outdir, prefix, filename.rstrip('.csv')+\".wgcna.summary_of_modules.csv\"), index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1ec632-1ab4-4459-93e7-f7d42978b160",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "###计算PCKMeans参数K的学习曲线###\n",
    "##########################################\n",
    "print(\"Calculate the learning curve for K ==========>\")\n",
    "\n",
    "score = {'SI': [], 'CH': [], 'DBI': []}\n",
    "\n",
    "# 读入约束基因集，构建成对约束\n",
    "df = open(os.path.join(mlDir, prefix, prefix+\".ml.txt\"),'r')\n",
    "geneslist = df.readline().split(\"\\t\")\n",
    "geneslist.pop()#去掉最后的换行符\n",
    "ml = set()\n",
    "byt = df.readlines()\n",
    "df.close()\n",
    "for index,value in enumerate(byt):\n",
    "    temp = value.split(\"\\t\")\n",
    "    temp.pop()#默认删除最后一个元素，并返回值\n",
    "    #temp.remove(\"\\n\")#删除元素temp\n",
    "    byt[index] = temp\n",
    "    for i in range(len(temp)):\n",
    "        for j in range(i+1, len(temp)):\n",
    "            ml.add((geneslist.index(temp[i]),geneslist.index(temp[j])))\n",
    "print(\"Number of pairwise constraints:%d\\n\" % len(ml))\n",
    "\n",
    "K_sequence = range(2, math.ceil(WGCNA_K*1.2), 1) #range(6, 11, 1)\n",
    "print(\"K = \", list(K_sequence))\n",
    "for k in K_sequence:\n",
    "    print(\"---->K = %d\" % k)\n",
    "    try:\n",
    "        ### 测试PCKMeans聚类效果 ###\n",
    "        t1 = time.time()\n",
    "        pckm = PCKMeans(n_clusters=k) #, distance_type='euclidean'\n",
    "        pckm.fit(np.array(X), ml=ml)\n",
    "        t2 = time.time()\n",
    "        #print (\"the time of clustering is %.5fs\" % (t2 - t1))\n",
    "        pckm_labels = pckm.labels_ \n",
    "        #print(\"value_counts:\\n\", pd.DataFrame(pd.value_counts(pckm_labels)).T)     \n",
    "        n_clusters_ =len(np.unique(pckm_labels)) - (1 if -1 in pckm_labels else 0)\n",
    "        \n",
    "        SI = silhouette_score(X, pckm_labels)\n",
    "        CH = calinski_harabasz_score(X, pckm_labels)\n",
    "        DBI = davies_bouldin_score(X, pckm_labels)\n",
    "        score[\"SI\"].append(SI)\n",
    "        score[\"CH\"].append(CH)\n",
    "        score[\"DBI\"].append(DBI)\n",
    "        print(\"The average silhouette_score is :%.4f\" % SI)\n",
    "        # print(\"For n_clusters =\", n_clusters_, \"\\nThe average silhouette_score is :\", SI)\n",
    "        # print(\"Calinski-Harabasz Score\",  CH, \"\\nDavies Bouldin score is :\", DBI)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"\\n==============================\")\n",
    "        print(\"    Error processing %s\" % k)\n",
    "        print(\"    \", e)\n",
    "        score[\"SI\"].append(0)\n",
    "        score[\"CH\"].append(0)\n",
    "        score[\"DBI\"].append(0)\n",
    "\n",
    "        print(\"==============================\\n\")\n",
    "        continue\n",
    "\n",
    "default_K = K_sequence[score[\"SI\"].index(np.max(score[\"SI\"]))]\n",
    "print('The optimal K value:%d' % default_K)\n",
    "xticks = list(K_sequence)\n",
    "\n",
    "pd.DataFrame.from_dict({'K_sequence':list(K_sequence) + [WGCNA_K]\n",
    "                        ,'SI':score[\"SI\"] + [assess['wgcna'][\"SI\"]]\n",
    "                        ,\"CH\":score[\"CH\"] + [assess['wgcna'][\"CH\"]]\n",
    "                        ,\"DBI\":score[\"DBI\"] + [assess['wgcna'][\"DBI\"]]\n",
    "                        ,'type':['pckmeans']*len(K_sequence)+['wgcna']}\n",
    "               ).to_csv(os.path.join(outdir, prefix, \"%s.K_learn-curve.csv\" % filename.rstrip('.csv')), index=False, sep=',')\n",
    "\n",
    "\n",
    "\n",
    "###################################################\n",
    "### Visualization of the learning curve  ###\n",
    "###################################################\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "fig.set_size_inches(18, 6)\n",
    "\n",
    "#xticks = range(len(score_pckmeans[\"SI\"][prefix_index]))# K_sequence #\n",
    "\n",
    "ax1.plot(xticks, score[\"SI\"]\n",
    "         , color = 'green', linewidth = 1.0, linestyle = '--', label='ScC-WGCNA', marker='^', markerfacecolor='green', markersize=10)\n",
    "ax1.scatter(WGCNA_K, assess['wgcna'][\"SI\"], s=100, c='r', marker='*',alpha=0.8)\n",
    "ax1.set_xlabel('K', fontdict={'size': 16})\n",
    "ax1.set_ylabel('Silhouette Coefficient Score', fontdict={'size': 16})\n",
    "ax1.set_title(\"SI\", fontdict={'size': 18})\n",
    "ax1.legend(loc='best')\n",
    "\n",
    "ax2.plot(xticks, score[\"CH\"]\n",
    "         , color = 'green', linewidth = 1.0, linestyle = '--', label='ScC-WGCNA', marker='^', markerfacecolor='green', markersize=10)\n",
    "ax2.scatter(WGCNA_K, assess['wgcna'][\"CH\"], s=100, c='r', marker='*',alpha=0.8)\n",
    "ax2.set_xlabel('K', fontdict={'size': 16})\n",
    "ax2.set_ylabel('Calinski Harabasz Score', fontdict={'size': 16})\n",
    "ax2.set_title(\"CH\", fontdict={'size': 18})\n",
    "ax2.legend(loc='best')\n",
    "\n",
    "ax3.plot(xticks, score[\"DBI\"]\n",
    "         , color = 'green', linewidth = 1.0, linestyle = '--', label='ScC-WGCNA', marker='^', markerfacecolor='green', markersize=10)\n",
    "ax3.scatter(WGCNA_K, assess['wgcna'][\"DBI\"], s=100, c='r', marker='*',alpha=0.8)\n",
    "ax3.set_xlabel('K', fontdict={'size': 16})\n",
    "ax3.set_ylabel('Davies Bouldin Score', fontdict={'size': 16})\n",
    "ax3.set_title(\"DBI\", fontdict={'size': 18})\n",
    "ax3.legend(loc='best')\n",
    "\n",
    "plt.suptitle((\"Learning curve for K values of ScC-WGCNA clustering on %s data\" % prefix), fontsize=20, fontweight='bold')\n",
    "fig = plt.gcf()\n",
    "fig.savefig(os.path.join(outdir, prefix, \"%s.Learning curve for K values of ScC-WGCNA clustering on %s data.pdf\" % (filename.rstrip('.csv'), filename.split('.')[0])), bbox_inches='tight')#\n",
    "fig.savefig(os.path.join(outdir, prefix, \"%s.Learning curve for K values of ScC-WGCNA clustering on %s data.png\" % (filename.rstrip('.csv'), filename.split('.')[0])), dpi=1080, bbox_inches='tight')#\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdca25c4-afd0-44d4-8dca-b00687d11cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##############################################################################################################################\n",
    "### 对m种聚类算法用三种外部聚类评估指标进行对比评估 以学习曲线选取最佳K值设置K 可以设置共表达网络构建所用的距离度量方法 ###\n",
    "##############################################################################################################################\n",
    "print(\"PCKMeans==========>\")\n",
    "\n",
    "K = WGCNA_K # default_K if default_K>3 else K_sequence[score[\"SI\"].index(np.max(score[\"SI\"][1:]))]\n",
    "\n",
    "# 读入约束基因集，构建成对约束\n",
    "df = open(os.path.join(mlDir, prefix, prefix+\".ml.txt\"),'r')\n",
    "geneslist = df.readline().split(\"\\t\")\n",
    "geneslist.pop()#去掉最后的换行符\n",
    "ml = set()\n",
    "byt = df.readlines()\n",
    "for index,value in enumerate(byt):\n",
    "    temp = value.split(\"\\t\")\n",
    "    temp.pop()#默认删除最后一个元素，并返回值\n",
    "    #temp.remove(\"\\n\")#删除元素temp\n",
    "    byt[index] = temp\n",
    "    for i in range(len(temp)):\n",
    "        for j in range(i+1, len(temp)):\n",
    "            ml.add((geneslist.index(temp[i]),geneslist.index(temp[j])))\n",
    "print(\"Number of pairwise constraints:%d\\n\" % len(ml))\n",
    "\n",
    "\n",
    "### PCKMeans聚类 ###\n",
    "\n",
    "t1 = time.time()\n",
    "pckm = PCKMeans(n_clusters=K)#, distance_type='euclidean'\n",
    "pckm.fit(np.array(X), ml=ml)#\n",
    "t2 = time.time()\n",
    "print (\"the time of clustering is %.5fs\" % (t2 - t1))\n",
    "pckm_labels = pckm.labels_\n",
    "\n",
    "\n",
    "print(\"value_counts:\\n\", pd.DataFrame(pd.value_counts(pckm_labels)).T)\n",
    "labels_counts = pd.DataFrame(pd.value_counts(pckm_labels, sort=False, ascending=False, normalize=False))\n",
    "labels_counts.insert(0, \"clusters\", labels_counts.index)\n",
    "labels_counts.columns = [\"clusters\", \"counts\"]\n",
    "labels_counts.to_csv(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".PCKMeans_clustering.labels_counts.csv\"), index=False)\n",
    "pd.DataFrame(np.array([X.index, pckm_labels]).T, columns=[\"gene\", \"labels\"]).to_csv(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".PCKMeans_clustering.cluster_labels.csv\"), index=False)#, header=None\n",
    "\n",
    "\n",
    "unique_labels = np.unique(pckm_labels)\n",
    "n_clusters_ =len(np.unique(pckm_labels)) - (1 if -1 in pckm_labels else 0)\n",
    "\n",
    "\n",
    "# 参数评估\n",
    "SI = silhouette_score(X, pckm_labels)\n",
    "CH = calinski_harabasz_score(X, pckm_labels)\n",
    "DBI = davies_bouldin_score(X, pckm_labels)\n",
    "assess['pckmeans'][\"SI\"] = SI\n",
    "assess['pckmeans'][\"CH\"] = CH\n",
    "assess['pckmeans'][\"DBI\"] = DBI\n",
    "print(\"For n_clusters =\", n_clusters_,\n",
    "        \"\\nThe average silhouette_score is :\", SI)\n",
    "print(\"Calinski-Harabasz Score\",  CH,\n",
    "         \"\\nDavies Bouldin score is :\", DBI)\n",
    "\n",
    "sample_silhouette_values = silhouette_samples(X, pckm_labels)\n",
    "\n",
    "# Silhouette analysis for clustering\n",
    "colors = Labels2Color(X, pckm_labels)['colorcode']\n",
    "SilhouetteAnalysis(X_Dim=X_Dim\n",
    "                   , labels=pckm_labels\n",
    "                   , SI=SI\n",
    "                   , sample_silhouette_values=sample_silhouette_values\n",
    "                   , dirPrefix=os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".Silhouette analysis for ScC-WGCNA clustering on %s data\" % prefix)\n",
    "                   , suptitle=\"Silhouette analysis for ScC-WGCNA clustering on %s data with n_clusters = %d\" % (prefix, n_clusters_)\n",
    "                   , colors=colors\n",
    "                   , showplot=True\n",
    "                   , D3=False\n",
    "                  )\n",
    "\n",
    "pd.DataFrame.from_dict(assess).to_csv(os.path.join(outdir, prefix, filename.rstrip('.csv')+\".ScC-WGCNA_vs_WGCNA.assess.csv\"), sep=',',index=True)\n",
    "\n",
    "\n",
    "#每个模块的基因数条形图\n",
    "bar(x=labels_counts.loc[:, \"clusters\"], y=labels_counts.loc[:, \"counts\"]\n",
    "    , dirPrefix=os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".Number of genes in the module\")\n",
    "    # , title=\"Number of genes in the module\"\n",
    "    , xlabel=\"Module\"\n",
    "    , ylabel=\"Number of genes\")\n",
    "\n",
    "genes_count = pd.DataFrame.from_dict({\"Module\":labels_counts.loc[:, \"clusters\"]\n",
    "                        , \"Number of genes\":labels_counts.loc[:, \"counts\"]})\n",
    "# genes_count.to_csv(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".Number of genes in the module.csv\")\n",
    "#                                                                            , index=False, sep=',')\n",
    "\n",
    "#模块内平均连通性\n",
    "values = []\n",
    "for k in np.sort(np.unique(pckm_labels)):      \n",
    "    values.append(sum(Connectivity.loc[pckm_labels==k, pckm_labels==k].sum())/sum(pckm_labels==k))\n",
    "bar(x=np.sort(np.unique(pckm_labels)), y=values\n",
    "    , dirPrefix=os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".Mean_Connectivity_of_module\")\n",
    "    # , title=\"Mean Connectivity of module\"\n",
    "    , xlabel=\"Module\"\n",
    "    , ylabel=\"Mean Connectivity\")\n",
    "\n",
    "Mean_Connectivity = pd.DataFrame.from_dict({'Module':np.sort(np.unique(pckm_labels)), 'Mean Connectivity':values})\n",
    "# Mean_Connectivity.to_csv(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".Mean_Connectivity_of_module.csv\")\n",
    "#                                                    , index=False, sep=',')\n",
    "\n",
    "#模块密度\n",
    "values = []\n",
    "for k in np.sort(np.unique(pckm_labels)):\n",
    "    values.append(sum(Connectivity.loc[pckm_labels==k, pckm_labels==k].sum())/(sum(pckm_labels==k)*(sum(pckm_labels==k)-1)))\n",
    "assess['pckmeans']['module_density_max'] = max(values)\n",
    "bar(x=np.sort(np.unique(pckm_labels)), y=values\n",
    "    , dirPrefix=os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".density_of_module\")\n",
    "    # , title=\"Density of module\"\n",
    "    , xlabel=\"Module\"\n",
    "    , ylabel=\"Density\")\n",
    "\n",
    "Density = pd.DataFrame.from_dict({'Module':np.sort(np.unique(pckm_labels)), 'Density':values})\n",
    "# Density.to_csv(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".density_of_module.csv\")\n",
    "#                                                    , index=False, sep=',')\n",
    "\n",
    "from functools import reduce\n",
    "summary = reduce(lambda left,right: pd.merge(left, right, on=['Module'], how='outer'), [genes_count, Mean_Connectivity, Density])\n",
    "summary.sort_values(by='Module', axis=0, ascending=True, inplace=True, ignore_index=True)\n",
    "summary.to_csv(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".summary_of_modules.csv\"), index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f55195-e293-49ff-bb74-a09a6fa63394",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "### The visualization of the clustered data ###\n",
    "###########################################################\n",
    "\n",
    "# datExpr = pd.read_csv(os.path.join(data_indir, prefix, filename), sep=',', index_col=0)\n",
    "\n",
    "# import umap.umap_ as umap\n",
    "# X_Dim = umap.UMAP(n_components=3).fit_transform(datExpr)\n",
    "\n",
    "# pckm_labels = pd.read_csv(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".PCKMeans_clustering.cluster_labels.csv\"))['labels'].tolist()\n",
    "# wgcna_labels = pd.read_csv(os.path.join(outdir, prefix, filename.rstrip('.csv')+\".WGCNA_clustering.cluster_labels.csv\"))['labels'].tolist()\n",
    "\n",
    "# WGCNA_K = len(np.unique(wgcna_labels))\n",
    "# K = WGCNA_K\n",
    "# WGCNA_K\n",
    "\n",
    "plt.clf() # 使用 plt.clf() 清理掉 axes\n",
    "# set up a figure twice as wide as it is tall\n",
    "fig = plt.figure(figsize=(16, 6), dpi=200)# 创建画布, 并设置分辨率为 80像素/每英寸\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.set_size_inches(18, 7) \n",
    "plt.rcParams.update({'font.family': 'Times New Roman'})\n",
    "plt.rcParams.update({'font.weight': 'normal'})\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "colors1 = Labels2Color(X, wgcna_labels)['colorcode']\n",
    "# set up the axes for the first plot\n",
    "ax1.axis('off')\n",
    "ax1 = fig.add_subplot(1, 2, 1) #, projection='3d'\n",
    "ax1.scatter(X_Dim[:, 0], X_Dim[:, 1]#3D, X_Dim[:, 2]\n",
    "           ,marker='o'\n",
    "           ,s=4\n",
    "           ,c=colors1\n",
    "           )\n",
    "ax1.set_title(\"WGCNA with n_clusters = %d\" % WGCNA_K, fontsize=18)\n",
    "ax1.set_xlabel(\"Feature space for the 1st feature\", fontsize=16)\n",
    "ax1.set_ylabel(\"Feature space for the 2nd feature\", fontsize=16)\n",
    "# ax1.set_zlabel(\"z\", fontsize=16)\n",
    "\n",
    "# ax1.spines['top'].set_visible(False)\n",
    "# ax1.spines['right'].set_visible(False)\n",
    "# ax1.spines['bottom'].set_visible(False)\n",
    "# ax1.spines['left'].set_visible(False)\n",
    "\n",
    "colors2 = Labels2Color(X, pckm_labels)['colorcode']\n",
    "# set up the axes for the first plot\n",
    "ax2.axis('off')\n",
    "ax2 = fig.add_subplot(1, 2, 2)#, projection='3d'\n",
    "\n",
    "ax2.scatter(X_Dim[:, 0], X_Dim[:, 1]#3D, X_Dim[:, 2]\n",
    "           ,marker='o'\n",
    "           ,s=4\n",
    "           ,c=colors2\n",
    "           )\n",
    "ax2.set_title(\"ScC-WGCNA with n_clusters = %d\" % K, fontsize=18)\n",
    "ax2.set_xlabel(\"Feature space for the 1st feature\", fontsize=16)\n",
    "ax2.set_ylabel(\"Feature space for the 2nd feature\", fontsize=16)\n",
    "# ax2.set_zlabel(\"z\", fontsize=16)\n",
    "\n",
    "# ax2.spines['top'].set_visible(False)\n",
    "# ax2.spines['right'].set_visible(False)\n",
    "# ax2.spines['bottom'].set_visible(False)\n",
    "# ax2.spines['left'].set_visible(False)\n",
    "plt.suptitle((\"The visualization of %s data clustering results\" % prefix),fontsize=20, fontweight='bold')\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.savefig(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".the visualization of %s data with WGCNA and ScC-WGCNA clustering results.png\" % prefix)\n",
    "            , bbox_inches='tight', dpi=1080)\n",
    "fig.savefig(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".the visualization of %s data with WGCNA and ScC-WGCNA clustering results.pdf\" % prefix)\n",
    "            , bbox_inches='tight')\n",
    "# plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c96b86d-bcda-4aa1-9a6a-5bbdf79b4e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d2cb2e0-2067-4e2f-9f24-f6ce54f09be3",
   "metadata": {},
   "source": [
    "### summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fcc196-4568-4dad-913d-83834660a0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mldir = \"E:/Project/Project001 WGCNA/main/step-6-FactorAnalyzer/outdir\"\n",
    "# data_indir = \"E:/Project/Project001 WGCNA/main/step-3-FeatureSelection/outdir\"\n",
    "# labelsdir = \"E:/Project/Project001 WGCNA/main/step-4-wgcna/outdir\"\n",
    "out_dir = \"E:/Project/Project001 WGCNA/main/step-7-clustering/semi_supervised Kmeans/outdir\"\n",
    "# dcorr_dir = \"E:/Project/Project001 WGCNA/main/step-7-clustering/Calculate the correlation coefficient/outdir\"\n",
    "\n",
    "distance = \"dcorr\" #\"pearson\" #\n",
    "\n",
    "filename = '.tcga_gtex.tpm.updown.feature_selection.csv'\n",
    "# filename = '.tumor.tpm.updown.feature_selection.csv'\n",
    "prefix = filename.split('.')[0]\n",
    "\n",
    "mlDir = '/'.join([mldir, filename.split('.')[1]])\n",
    "# labelsDir = '/'.join([labelsdir, filename.split('.')[1]])\n",
    "# outdir = os.path.join(outdir, filename.split('.'))\n",
    "outdir = '/'.join([out_dir, filename.split('.')[1], distance])\n",
    "# dcorrDir = '/'.join([dcorr_dir, filename.split('.')[1]])\n",
    "\n",
    "if not os.path.exists(os.path.join(outdir, prefix)):\n",
    "    os.makedirs(os.path.join(outdir, prefix))\n",
    "    \n",
    "\n",
    "cancer_names = [\"BLCA\", \"BRCA\", \"COAD\", \"KIRC\", \"LUAD\", \"LUSC\", \"STAD\",  \"PAAD\"]#\n",
    "distance_metrics = [\"euclidean\", \"snn\", \"dcorr\", \"pearson\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c096191b-8ce5-4f28-8818-39dbf154ca36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################\n",
    "####### summary  #######\n",
    "########################\n",
    "\n",
    "assess = dict(wgcna = dict(datasets = {}, SI = {}, CH = {}, DBI = {}, module_density_max = {})\n",
    "              , pckmeans = dict(datasets = {}, SI = {}, CH = {}, DBI = {}, module_density_max = {}))\n",
    "\n",
    "for cancer in cancer_names:\n",
    "    prefix = cancer\n",
    "    temp = pd.read_csv(os.path.join(outdir, prefix, prefix+filename.rstrip('.csv')+\".ScC-WGCNA_vs_WGCNA.assess.csv\"), sep=',', index_col=0)\n",
    "    temp.to_dict()\n",
    "    for key1 in ['wgcna', 'pckmeans']:\n",
    "        assess[key1]['datasets'][cancer] = cancer\n",
    "        for key2 in ['SI', 'CH', 'DBI', 'module_density_max']:\n",
    "            assess[key1][key2][cancer] = temp[key1][key2]\n",
    "\n",
    "temp1 = pd.DataFrame.from_dict(assess['pckmeans'])\n",
    "temp1.columns = ['.'.join([x, 'ScC-WGCNA']) if x!='datasets' else x for x in temp1.columns if isinstance(x, str)]\n",
    "temp2 = pd.DataFrame.from_dict(assess['wgcna'])\n",
    "temp2.columns = ['.'.join([x, 'WGCNA']) if x!='datasets' else x for x in temp2.columns if isinstance(x, str)]\n",
    "pd.merge(temp1, temp2, on='datasets', how='outer').to_csv(os.path.join(outdir, distance+\".ScC-WGCNA_vs_WGCNA.assess.csv\"), index=False)\n",
    "\n",
    "module_density_max = {}\n",
    "module_density_max['WGCNA'] = assess['wgcna']['module_density_max']\n",
    "module_density_max['ScC-WGCNA'] = assess['pckmeans']['module_density_max']\n",
    "moduleDensity_max = round(pd.DataFrame.from_dict(module_density_max, orient= 'index'), 4)\n",
    "moduleDensity_max.to_csv(os.path.join(outdir, distance+\".module_density_max.csv\"), index=True)\n",
    "\n",
    "ml_summary = {'Number of gene':{}, 'Number of gene pair':{}, 'Number of constrained gene':{}}\n",
    "for cancer in cancer_names:\n",
    "    prefix = cancer\n",
    "    # 读入约束基因集，构建成对约束\n",
    "    df = open(os.path.join(mlDir, prefix, prefix+\".ml.txt\"),'r')\n",
    "    geneslist = df.readline().split(\"\\t\")\n",
    "    geneslist.pop()#去掉最后的换行符\n",
    "    ml_summary['Number of gene'][prefix] = len(geneslist)\n",
    "    \n",
    "    ml = set()\n",
    "    byt = df.readlines()\n",
    "    for index,value in enumerate(byt):\n",
    "        temp = value.split(\"\\t\")\n",
    "        temp.pop()#默认删除最后一个元素，并返回值\n",
    "        #temp.remove(\"\\n\")#删除元素temp\n",
    "        byt[index] = temp\n",
    "        for i in range(len(temp)):\n",
    "            for j in range(i+1, len(temp)):\n",
    "                ml.add((geneslist.index(temp[i]),geneslist.index(temp[j])))\n",
    "    ml_summary['Number of gene pair'][prefix] = len(ml)\n",
    "    print(\"Number of pairwise constraints:%d\\n\" % len(ml))\n",
    "    \n",
    "    temp = []\n",
    "    for u,v in ml:\n",
    "        temp += [u,v]\n",
    "    ml_summary['Number of constrained gene'][prefix] = round(len(set(temp))/len(geneslist), 4)\n",
    "    print(\"Number of constrained gene:%d\\n\" % len(set(temp)))\n",
    "\n",
    "pd.DataFrame.from_dict(ml_summary, orient= 'index').to_csv(os.path.join(outdir, distance+\".summary of pairwise constraints.csv\"), index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396daf83-ae29-48e1-b802-98291f970547",
   "metadata": {},
   "source": [
    "### The visualization of the  evaluation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6a6c49-db38-4d76-b7bf-a70bfeb7686d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "### The visualization of the  evaluation score  ###\n",
    "###########################################################\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "fig.set_size_inches(24, 8)\n",
    "# plt.rcParams['xtick.labelsize']=12\n",
    "# plt.rcParams['ytick.labelsize']=12\n",
    "\n",
    "x = cancer_names #range(len(score_wgcna[\"SI\"]))# \n",
    "ax1.plot(assess['wgcna'][\"SI\"].keys(), assess['wgcna'][\"SI\"].values(), color = 'red'\n",
    "         , linewidth = 1.0, linestyle = '-', label='WGCNA', marker='d', markerfacecolor='red', markersize=10)\n",
    "ax1.plot(assess['pckmeans'][\"SI\"].keys(), assess['pckmeans'][\"SI\"].values(), color = 'green'\n",
    "         , linewidth = 1.0, linestyle = '--', label='ScC-WGCNA', marker='^', markerfacecolor='green', markersize=10)\n",
    "ax1.set_xlabel('datasets', fontdict={'size': 16})\n",
    "ax1.set_ylabel('Silhouette Coefficient Score', fontdict={'size': 16})\n",
    "ax1.set_title(\"SI\", fontdict={'size': 18})\n",
    "ax1.legend(loc='best', fontsize = 12)\n",
    "ax1.set_xticklabels(assess['wgcna'][\"SI\"].keys(), rotation = 30, fontsize = 12)\n",
    "plt.setp(ax1.get_yticklabels(), fontsize=12)\n",
    "\n",
    "ax2.plot(assess['wgcna'][\"CH\"].keys(), assess['wgcna'][\"CH\"].values(), color = 'red'\n",
    "         , linewidth = 1.0, linestyle = '-', label='WGCNA', marker='d', markerfacecolor='red', markersize=10)\n",
    "ax2.plot(assess['pckmeans'][\"CH\"].keys(), assess['pckmeans'][\"CH\"].values(), color = 'green'\n",
    "         , linewidth = 1.0, linestyle = '--', label='ScC-WGCNA', marker='^', markerfacecolor='green', markersize=10)\n",
    "ax2.set_xlabel('datasets', fontdict={'size': 16})\n",
    "ax2.set_ylabel('Calinski Harabasz Score', fontdict={'size': 16})\n",
    "ax2.set_title(\"CH\", fontdict={'size': 18})\n",
    "ax2.legend(loc='best', fontsize = 12)\n",
    "ax2.set_xticklabels(assess['wgcna'][\"CH\"].keys(), rotation = 30, fontsize = 12)\n",
    "plt.setp(ax2.get_yticklabels(), fontsize=12)\n",
    "\n",
    "ax3.plot(assess['wgcna'][\"DBI\"].keys(), assess['wgcna'][\"DBI\"].values(), color = 'red'\n",
    "         , linewidth = 1.0, linestyle = '-', label='WGCNA', marker='d', markerfacecolor='red', markersize=10)\n",
    "ax3.plot(assess['pckmeans'][\"DBI\"].keys(), assess['pckmeans'][\"DBI\"].values(), color = 'green'\n",
    "         , linewidth = 1.0, linestyle = '--', label='ScC-WGCNA', marker='^', markerfacecolor='green', markersize=10)\n",
    "ax3.set_xlabel('datasets', fontdict={'size': 16})\n",
    "ax3.set_ylabel('Davies Bouldin Score', fontdict={'size': 16})\n",
    "ax3.set_title(\"DBI\", fontdict={'size': 18})\n",
    "ax3.legend(loc='best', fontsize = 12)\n",
    "ax3.set_xticklabels(assess['wgcna'][\"DBI\"].keys(), rotation = 30, fontsize = 12)\n",
    "plt.setp(ax3.get_yticklabels(), fontsize=12)\n",
    "\n",
    "plt.suptitle((\"SI,CH and DBI scores for WGCNA and ScC-WGCNA clustering on datasets\"), fontsize=20, fontweight='bold')\n",
    "fig = plt.gcf()\n",
    "fig.savefig(os.path.join(outdir, distance+\".SI,CH and DBI scores for WGCNA and ScC-WGCNA clustering on datasets.png\")\n",
    "            , bbox_inches='tight', dpi=1080)\n",
    "fig.savefig(os.path.join(outdir, distance+\".SI,CH and DBI scores for WGCNA and ScC-WGCNA clustering on datasets.pdf\"), bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
