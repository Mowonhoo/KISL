{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde7e9b9-4ef2-435c-9d7e-520cee6a2590",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import os,re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "# 这两行代码解决 plt 中文显示的问题\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score, calinski_harabasz_score # CH 指标，DBI \n",
    "from sklearn.metrics import silhouette_samples, silhouette_score # 轮廓系数\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.spatial.distance import cdist#cdist(XA, XB, 'correlation')\n",
    "from dcor import distance_correlation as dcorr\n",
    "from scipy.stats import pearsonr\n",
    "#    1）输入：x为特征，y为目标变量.\n",
    "#    2）输出：r： 相关系数 [-1，1]之间，p-value: p值。\n",
    "#         注： p值越小，表示相关系数越显著，一般p值在500个样本以上时有较高的可靠性。\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from matplotlib.axes._axes import _log as matplotlib_axes_logger\n",
    "matplotlib_axes_logger.setLevel('ERROR')#日志只显示error级别的错误\n",
    "\n",
    "from pckmeans import PCKMeans\n",
    "from mpckmeans import MPCKMeans\n",
    "\n",
    "##my\n",
    "from labels2color import Labels2Color\n",
    "#from topological_overlap_measure import TOMsimilarity\n",
    "from topological_overlap_measure import *\n",
    "#from soothsayer.networks import topological_overlap_measure\n",
    "\n",
    "from my_functions import *\n",
    "\n",
    "# cancer_names = [\"BLCA\", \"BRCA\", \"COAD\", \"KIRC\", \"LUAD\", \"LUSC\", \"STAD\",  \"PAAD\"]#\n",
    "mldir = \"E:/Project/Project001 WGCNA/main/step-6-FactorAnalyzer/outdir\"\n",
    "data_indir = \"E:/Project/Project001 WGCNA/main/step-3-FeatureSelection/outdir\"\n",
    "labelsdir = \"E:/Project/Project001 WGCNA/main/step-4-wgcna/outdir\"\n",
    "out_dir = \"E:/Project/Project001 WGCNA/main/step-7-clustering/semi_supervised Kmeans/outdir\"\n",
    "dcorr_dir = \"E:/Project/Project001 WGCNA/main/step-7-clustering/Calculate the correlation coefficient/outdir\"\n",
    "\n",
    "distance = \"dcorr\" #\"pearson\" #\n",
    "power = 20\n",
    "filename = 'LUAD.tcga_gtex.tpm.updown.feature_selection.csv'\n",
    "# filename = 'BLCA.tumor.tpm.updown.feature_selection.csv'\n",
    "prefix = filename.split('.')[0]\n",
    "\n",
    "mldir = '/'.join([mldir, filename.split('.')[1]])\n",
    "labelsdir = '/'.join([labelsdir, filename.split('.')[1]])\n",
    "# outdir = os.path.join(outdir, filename.split('.'))\n",
    "outdir = '/'.join([out_dir, filename.split('.')[1], distance])\n",
    "dcorr_dir = '/'.join([dcorr_dir, filename.split('.')[1]])\n",
    "\n",
    "if not os.path.exists(os.path.join(outdir, prefix)):\n",
    "    os.makedirs(os.path.join(outdir, prefix))\n",
    "    \n",
    "assess = dict(wgcna = dict(SI = 0, CH = 0, DBI = 0, module_density_max = 0)\n",
    "              , pckmeans = dict(SI = 0, CH = 0, DBI = 0, module_density_max = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefe12a3-c16b-4787-bc3a-33556e160267",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "### 构建GCN网络计算dissTOM矩阵 ###\n",
    "##########################################\n",
    "if distance == \"pearson\":\n",
    "    data = pd.read_csv(os.path.join(data_indir, prefix, filename), sep=',', index_col=0)\n",
    "    print(\"Input: data.shape\", data.shape)\n",
    "    print(\"NAN check for data: \", data.isnull().values.sum())\n",
    "    sim = data.T.corr()#dcor## # 计算pearson相关系数，得到相似矩阵\n",
    "elif distance == \"snn\":\n",
    "    data = pd.read_csv(os.path.join(data_indir, prefix, filename), sep=',', index_col=0)\n",
    "    print(\"Input: data.shape\", data.shape)\n",
    "    print(\"NAN check for data: \", data.isnull().values.sum())\n",
    "    sim = snn_sim_matrix(data, k=5)\n",
    "elif distance == \"dcorr\":\n",
    "    sim = pd.read_csv(os.path.join(dcorr_dir, prefix, filename.rstrip('.csv')+\".dcorr.csv\"), sep=',')\n",
    "    sim.index = sim.columns\n",
    "else:\n",
    "    print(\"input parameter error：Undefined distance type.\")\n",
    "\n",
    "print(\"NAN check: \", sim.isnull().values.sum())\n",
    "#先删除全是空值的行和列\n",
    "if sim.isnull().values.ravel().sum():\n",
    "    sim.drop(sim.columns[sim.isnull().all(axis=1)].tolist(), inplace=True)#删除全是NAN的行\n",
    "    sim = sim[sim.columns[~sim.isnull().all(axis=0)].tolist()]#删除全是NAN的列\n",
    "    #再用0填充NAN\n",
    "    sim.fillna(0, inplace=True)#用0填补缺失值\n",
    "print(\"After processing NA: sim.shape\", sim.shape)\n",
    "sim.to_csv(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".sim.csv\"), index=False, sep=',')\n",
    "\n",
    "\n",
    "# 调用R script计算软阈值\n",
    "sft = pickSoftThreshold(sim, power=power, RsquaredCut = 0.75, prefix=prefix, outdir=outdir)\n",
    "print('powerEstimate:%s' % sft[\"powerEstimate\"])\n",
    "sft[\"fitIndices\"].to_csv(os.path.join(outdir, prefix, filename.rstrip('.csv')+\"sft_fitIndices.csv\"), index=False, sep=',')\n",
    "\n",
    "\n",
    "#Check scale free topology\n",
    "# Create an adjacency network； ^6 近似无标度化\n",
    "# here we define the adjacency matrix using soft thresholding with beta=6\n",
    "ADJ = abs(sim)**sft[\"powerEstimate\"] # 近似无标度化\n",
    "print(\"Input: ADJ\", \"Max: {}\".format(ADJ.values.ravel().max()), \"Min: {}\".format(ADJ.values.ravel().min()), sep=\"\\n\")\n",
    "print(\"NAN check: \", ADJ.isnull().values.sum())\n",
    "ADJ.to_csv(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".ADJ.csv\"), index=False, sep=',')\n",
    "\n",
    "#计算邻接性\n",
    "Connectivity = ADJ.values\n",
    "row, col = np.diag_indices_from(Connectivity)\n",
    "Connectivity[row, col] = 0\n",
    "Connectivity = pd.DataFrame(Connectivity, columns=ADJ.columns)\n",
    "Connectivity.to_csv(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".Connectivity.csv\"), index=False, sep=',')\n",
    "\n",
    "# Compute topological overlap\n",
    "#from topological_overlap_measure import TOMsimilarity\n",
    "from topological_overlap_measure import *\n",
    "#from soothsayer.networks import topological_overlap_measure\n",
    "TOM = TOMsimilarity(ADJ)#把邻接矩阵转换为拓扑重叠矩阵topological_overlap_measure\n",
    "dissTOM = 1 - TOM\n",
    "\n",
    "TOM.to_csv(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".TOM.csv\"), index=False, sep=',')\n",
    "dissTOM.to_csv(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".dissTOM.csv\"), index=False, sep=',')\n",
    "\n",
    "X = dissTOM.copy()\n",
    "\n",
    "\n",
    "try:\n",
    "    import umap.umap_ as umap\n",
    "    X_Dim = umap.UMAP(n_components=3).fit_transform(X)\n",
    "    # 使用TSNE进行降维处理\n",
    "    # X_Dim = TSNE(n_components=3, learning_rate=100, random_state=0).fit_transform(X)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"Data dimension reduction failed.\\n\")\n",
    "    print(e)\n",
    "    print(\"==============================\\n\")\n",
    "    # X_Dim = TSNE(n_components=2, learning_rate=100, random_state=0).fit_transform(ADJ)\n",
    "    X_Dim = umap.UMAP(n_components=3).fit_transform(ADJ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded7b2c2-af7e-415e-9cb1-a9adb86cfcd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "### 可视化WGCNA聚类结果作为参考 ###\n",
    "##########################################\n",
    "print(\"WGCNA==========>\")\n",
    "method = 'WGCNA'\n",
    "wgcna_y_pred = pd.read_csv(os.path.join(labelsdir, prefix, prefix+\".wgcna.result.csv\"), index_col=False)\n",
    "wgcna_y_pred.index = wgcna_y_pred[\"gene\"].values\n",
    "wgcna_y_pred = wgcna_y_pred.loc[X.index]\n",
    "wgcna_labels = wgcna_y_pred[\"dynamicMods\"].values\n",
    "#print(\"value_counts:\\n\", pd.DataFrame(pd.value_counts(wgcna_labels)).T)\n",
    "labels_counts = pd.DataFrame(pd.value_counts(wgcna_labels))\n",
    "labels_counts.insert(0, \"clusters\", labels_counts.index)\n",
    "labels_counts.columns = [\"clusters\", \"counts\"]\n",
    "labels_counts.to_csv(os.path.join(outdir, prefix, filename.rstrip('.csv')+\".%s_clustering.labels_counts.csv\" % method), index=False)\n",
    "pd.DataFrame(np.array([X.index, wgcna_labels]).T\n",
    "             , columns=[\"gene\", \"labels\"]\n",
    "            ).to_csv(os.path.join(outdir, prefix, filename.rstrip('.csv')+\".%s_clustering.cluster_labels.csv\" % method), index=False)#, header=None\n",
    "\n",
    "unique_labels = np.unique(wgcna_labels)\n",
    "##分类个数：lables中包含-1，表示噪声点\n",
    "n_clusters_ =len(np.unique(wgcna_labels)) - (1 if -1 in wgcna_labels else 0) \n",
    "print(\"Number of clusters with WGCNA:%d\" % n_clusters_)\n",
    "WGCNA_K = n_clusters_\n",
    "\n",
    "SI = silhouette_score(X, wgcna_labels)\n",
    "CH = calinski_harabasz_score(X, wgcna_labels)\n",
    "DBI = davies_bouldin_score(X, wgcna_labels)\n",
    "sample_silhouette_values = silhouette_samples(X, wgcna_labels)\n",
    "\n",
    "assess['wgcna'][\"SI\"] = SI\n",
    "assess['wgcna'][\"CH\"] = CH\n",
    "assess['wgcna'][\"DBI\"] = DBI\n",
    "print(\"For n_clusters =\", n_clusters_,\n",
    "        \"\\nThe average silhouette_score is :\", SI)\n",
    "print(\"Calinski-Harabasz Score\",  CH,\n",
    "         \"\\nDavies Bouldin score is :\", DBI)\n",
    "\n",
    "\n",
    "plt.clf() # 使用 plt.clf() 清理掉 axes\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.set_size_inches(18, 7)\n",
    "plt.rcParams.update({'font.family': 'Times New Roman'})\n",
    "plt.rcParams.update({'font.weight': 'normal'})\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "ax1=fig.add_subplot(121)\n",
    "ax1.set_xlim([-0.1, 1])\n",
    "ax1.set_ylim([0, X.shape[0] + (n_clusters_ + 1) * 10])\n",
    "\n",
    "\n",
    "y_lower = 10\n",
    "for i in range(n_clusters_):\n",
    "    ith_cluster_silhouette_values = sample_silhouette_values[wgcna_labels == i]\n",
    "    ith_cluster_silhouette_values.sort()\n",
    "    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "    y_upper = y_lower + size_cluster_i\n",
    "    color = cm.nipy_spectral(float(i)/n_clusters_)\n",
    "    ax1.fill_betweenx(np.arange(y_lower, y_upper)\n",
    "                     ,ith_cluster_silhouette_values\n",
    "                     ,facecolor=color\n",
    "                     ,alpha=0.7\n",
    "                     )\n",
    "    ax1.text(-0.05\n",
    "             , y_lower + 0.5 * size_cluster_i\n",
    "             , str(i))\n",
    "    y_lower = y_upper + 10\n",
    "ax1.set_title(\"The Silhouette plot for the various clusters.\", fontsize=18)\n",
    "ax1.set_xlabel(\"The Silhouette coefficient values\", fontsize=16)\n",
    "ax1.set_ylabel(\"Cluster label\", fontsize=16)\n",
    "ax1.axvline(x=SI, color=\"red\", linestyle=\"--\")\n",
    "ax1.set_yticks([])\n",
    "ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "#colors = cm.nipy_spectral(wgcna_labels.astype(float) / n_clusters_)\n",
    "colors = Labels2Color(X, wgcna_labels)['colorcode']\n",
    "ax2 = fig.add_subplot(1, 2, 2, projection='3d') \n",
    "ax2.scatter3D(X_Dim[:, 0], X_Dim[:, 1],X_Dim[:, 2]\n",
    "           ,marker='o'\n",
    "           ,s=4\n",
    "           ,c=colors\n",
    "           )\n",
    "\n",
    "ax2.set_title(\"The visualization of the clustered data.\", fontsize=18)\n",
    "ax2.set_xlabel(\"Feature space for the 1st feature\", fontsize=16)\n",
    "ax2.set_ylabel(\"Feature space for the 2nd feature\", fontsize=16)\n",
    "ax2.set_zlabel(\"z\", fontsize=20)\n",
    "plt.suptitle((\"Silhouette analysis for WGCNA clustering on %s data with n_clusters = %d\" % (prefix, WGCNA_K)),\n",
    "             fontsize=20, fontweight='bold')\n",
    "fig = plt.gcf()\n",
    "fig.savefig(os.path.join(outdir, prefix, filename.rstrip('.csv')+\".Silhouette analysis for WGCNA clustering on %s data.png\" % prefix)\n",
    "            , bbox_inches='tight', dpi=1080)\n",
    "fig.savefig(os.path.join(outdir, prefix, filename.rstrip('.csv')+\".Silhouette analysis for WGCNA clustering on %s data.pdf\" % prefix)\n",
    "            , bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "###画wgcna的基因数量图、模块平均连通性图和模块密度图###\n",
    "\n",
    "#每个模块的基因数条形图\n",
    "width = 0.35# 柱子的宽度\n",
    "fig = plt.figure(figsize=(6, 6), dpi=100)# 创建画布, 并设置分辨率为 80像素/每英寸\n",
    "# plt.clf() # 使用 plt.clf() 清理掉 axes\n",
    "plt.subplot(111)# 创建一个子图\n",
    "#plt.title(\"Number of genes in the module\", fontsize=18)\n",
    "plt.xlabel(\"Module\", fontsize=16)\n",
    "plt.ylabel(\"Number of genes\", fontsize=16)\n",
    "plt.bar(labels_counts.loc[:, \"clusters\"], labels_counts.loc[:, \"counts\"], width, color=\"#87CEFA\") # 绘制柱状图, 每根柱子的颜色为紫罗兰色\n",
    "fig.savefig(os.path.join(outdir, prefix, filename.rstrip('.csv')+\".wgcna.Number of genes in the module.png\"), dpi=1080, bbox_inches='tight')\n",
    "fig.savefig(os.path.join(outdir, prefix, filename.rstrip('.csv')+\".wgcna.Number of genes in the module.pdf\"), bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "#模块内平均连通性\n",
    "values = []\n",
    "for k in np.sort(np.unique(wgcna_labels)):      \n",
    "    values.append(sum(Connectivity.loc[wgcna_labels==k, wgcna_labels==k].sum())/sum(wgcna_labels==k))\n",
    "width = 0.35# 柱子的宽度\n",
    "fig = plt.figure(figsize=(6, 6), dpi=100)# 创建画布, 并设置分辨率为 80像素/每英寸\n",
    "# plt.clf() # 使用 plt.clf() 清理掉 axes\n",
    "plt.subplot(111)# 创建一个子图\n",
    "plt.title(\"Mean Connectivity of module\", fontsize=18)\n",
    "plt.xlabel(\"Module\", fontsize=16)\n",
    "plt.ylabel(\"Mean Connectivity\", fontsize=16)\n",
    "plt.bar(np.sort(np.unique(wgcna_labels)), values, width, color=\"#87CEFA\") # 绘制柱状图, 每根柱子的颜色为紫罗兰色ind-width/2\n",
    "fig.savefig(os.path.join(outdir, prefix, filename.rstrip('.csv')+\".wgcna.Mean_Connectivity_of_module.png\"), dpi=1080, bbox_inches='tight')\n",
    "fig.savefig(os.path.join(outdir, prefix, filename.rstrip('.csv')+\".wgcna.Mean_Connectivity_of_module.pdf\"), bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "#模块密度\n",
    "values = []\n",
    "for k in np.sort(np.unique(wgcna_labels)):      \n",
    "    values.append(sum(Connectivity.loc[wgcna_labels==k, wgcna_labels==k].sum())/(sum(wgcna_labels==k)*(sum(wgcna_labels==k)-1)))\n",
    "assess['wgcna']['module_density_max'] = max(values)\n",
    "width = 0.35# 柱子的宽度\n",
    "fig = plt.figure(figsize=(6, 6), dpi=100)# 创建画布, 并设置分辨率为 80像素/每英寸\n",
    "# plt.clf() # 使用 plt.clf() 清理掉 axes\n",
    "plt.subplot(111)# 创建一个子图\n",
    "#plt.title(\"Density of module\", fontsize=18)\n",
    "plt.xlabel(\"Module\", fontsize=16)\n",
    "plt.ylabel(\"Density of module\", fontsize=16)\n",
    "plt.bar(np.sort(np.unique(wgcna_labels)), values, width, color=\"#87CEFA\") # 绘制柱状图, 每根柱子的颜色为紫罗兰色ind-width/2\n",
    "fig.savefig(os.path.join(outdir, prefix, filename.rstrip('.csv')+\".wgcna.density_of_module.png\"), dpi=1080, bbox_inches='tight')\n",
    "fig.savefig(os.path.join(outdir, prefix, filename.rstrip('.csv')+\".wgcna.density_of_module.pdf\"), bbox_inches='tight')\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc93e65-5e7b-4680-9649-d6967429c0aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "###计算PCKMeans参数K的学习曲线###\n",
    "##########################################\n",
    "print(\"Calculate the learning curve for K ==========>\")\n",
    "\n",
    "score = {'SI': [], 'CH': [], 'DBI': []}\n",
    "# 读入约束条件，构建成对约束\n",
    "df = open(os.path.join(mldir, prefix, prefix+\".ml.txt\"),'r')\n",
    "geneslist = df.readline().split(\"\\t\")\n",
    "byt = df.readlines()\n",
    "df.close()\n",
    "geneslist.pop()#去掉最后的换行符\n",
    "ml = set()\n",
    "for index,value in enumerate(byt):\n",
    "    temp = value.split(\"\\t\")\n",
    "    temp.pop()#默认删除最后一个元素，并返回值\n",
    "    #temp.remove(\"\\n\")#删除元素temp\n",
    "    byt[index] = temp\n",
    "    for i in range(len(temp)):\n",
    "        for j in range(i+1, len(temp)):\n",
    "            ml.add((geneslist.index(temp[i]),geneslist.index(temp[j])))\n",
    "print(\"Constraints in pairs gene number:%d\" % len(ml))\n",
    "\n",
    "K_sequence = range(2, math.ceil(WGCNA_K*1.2), 1) #range(6, 11, 1)\n",
    "print(\"K = \", list(K_sequence))\n",
    "for k in K_sequence:\n",
    "    print(\"---->K = %d\" % k)\n",
    "    try:\n",
    "        ### 测试PCKMeans聚类效果 ###\n",
    "        t1 = time.time()\n",
    "        pckm = PCKMeans(n_clusters=k) #, distance_type='euclidean'\n",
    "        pckm.fit(np.array(X), ml=ml)\n",
    "        t2 = time.time()\n",
    "        #print (\"the time of clustering is %.5fs\" % (t2 - t1))\n",
    "        pckm_labels = pckm.labels_ \n",
    "        #print(\"value_counts:\\n\", pd.DataFrame(pd.value_counts(pckm_labels)).T)     \n",
    "        n_clusters_ =len(np.unique(pckm_labels)) - (1 if -1 in pckm_labels else 0)\n",
    "        \n",
    "        SI = silhouette_score(X, pckm_labels)\n",
    "        CH = calinski_harabasz_score(X, pckm_labels)\n",
    "        DBI = davies_bouldin_score(X, pckm_labels)\n",
    "        score[\"SI\"].append(SI)\n",
    "        score[\"CH\"].append(CH)\n",
    "        score[\"DBI\"].append(DBI)\n",
    "        print(\"The average silhouette_score is :%.4f\" % SI)\n",
    "        # print(\"For n_clusters =\", n_clusters_, \"\\nThe average silhouette_score is :\", SI)\n",
    "        # print(\"Calinski-Harabasz Score\",  CH, \"\\nDavies Bouldin score is :\", DBI)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"\\n==============================\")\n",
    "        print(\"    Error processing %s\" % k)\n",
    "        print(\"    \", e)\n",
    "        score[\"SI\"].append(0)\n",
    "        score[\"CH\"].append(0)\n",
    "        score[\"DBI\"].append(0)\n",
    "\n",
    "        print(\"==============================\\n\")\n",
    "        continue\n",
    "\n",
    "default_K = K_sequence[score[\"SI\"].index(np.max(score[\"SI\"]))]\n",
    "print('The optimal K value:%d' % default_K)\n",
    "xticks = list(K_sequence)\n",
    "\n",
    "pd.DataFrame.from_dict({'K_sequence':list(K_sequence) + [WGCNA_K]\n",
    "                        ,'SI':score[\"SI\"] + [assess['wgcna'][\"SI\"]]\n",
    "                        ,\"CH\":score[\"CH\"] + [assess['wgcna'][\"CH\"]]\n",
    "                        ,\"DBI\":score[\"DBI\"] + [assess['wgcna'][\"DBI\"]]\n",
    "                        ,'type':['pckmeans']*len(K_sequence)+['wgcna']}\n",
    "               ).to_csv(os.path.join(outdir, prefix, \"%s.K_learn-curve.csv\" % filename.rstrip('.csv')), index=False, sep=',')\n",
    "\n",
    "\n",
    "\n",
    "###################################################\n",
    "### Visualization of the learning curve  ###\n",
    "###################################################\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "fig.set_size_inches(18, 6)\n",
    "\n",
    "#xticks = range(len(score_pckmeans[\"SI\"][prefix_index]))# K_sequence #\n",
    "\n",
    "ax1.plot(xticks, score[\"SI\"]\n",
    "         , color = 'green', linewidth = 1.0, linestyle = '--', label='ScC-WGCNA', marker='^', markerfacecolor='green', markersize=10)\n",
    "ax1.scatter(WGCNA_K, assess['wgcna'][\"SI\"], s=100, c='r', marker='*',alpha=0.8)\n",
    "ax1.set_xlabel('K', fontdict={'size': 16})\n",
    "ax1.set_ylabel('Silhouette Coefficient Score', fontdict={'size': 16})\n",
    "ax1.set_title(\"SI\", fontdict={'size': 18})\n",
    "ax1.legend(loc='best')\n",
    "\n",
    "ax2.plot(xticks, score[\"CH\"]\n",
    "         , color = 'green', linewidth = 1.0, linestyle = '--', label='ScC-WGCNA', marker='^', markerfacecolor='green', markersize=10)\n",
    "ax2.scatter(WGCNA_K, assess['wgcna'][\"CH\"], s=100, c='r', marker='*',alpha=0.8)\n",
    "ax2.set_xlabel('K', fontdict={'size': 16})\n",
    "ax2.set_ylabel('Calinski Harabasz Score', fontdict={'size': 16})\n",
    "ax2.set_title(\"CH\", fontdict={'size': 18})\n",
    "ax2.legend(loc='best')\n",
    "\n",
    "ax3.plot(xticks, score[\"DBI\"]\n",
    "         , color = 'green', linewidth = 1.0, linestyle = '--', label='ScC-WGCNA', marker='^', markerfacecolor='green', markersize=10)\n",
    "ax3.scatter(WGCNA_K, assess['wgcna'][\"DBI\"], s=100, c='r', marker='*',alpha=0.8)\n",
    "ax3.set_xlabel('K', fontdict={'size': 16})\n",
    "ax3.set_ylabel('Davies Bouldin Score', fontdict={'size': 16})\n",
    "ax3.set_title(\"DBI\", fontdict={'size': 18})\n",
    "ax3.legend(loc='best')\n",
    "\n",
    "plt.suptitle((\"Learning curve for K values of ScC-WGCNA clustering on %s data\" % prefix), fontsize=20, fontweight='bold')\n",
    "fig = plt.gcf()\n",
    "fig.savefig(os.path.join(outdir, prefix, \"%s.Learning curve for K values of ScC-WGCNA clustering on %s data.pdf\" % (filename.rstrip('.csv'), filename.split('.')[0])), bbox_inches='tight')#\n",
    "fig.savefig(os.path.join(outdir, prefix, \"%s.Learning curve for K values of ScC-WGCNA clustering on %s data.png\" % (filename.rstrip('.csv'), filename.split('.')[0])), dpi=1080, bbox_inches='tight')#\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476b5f79-d65c-4e65-99d8-3393a80c10cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################################\n",
    "### 对m种聚类算法用三种外部聚类评估指标进行对比评估 以学习曲线选取最佳K值设置K 可以设置共表达网络构建所用的距离度量方法 ###\n",
    "##############################################################################################################################\n",
    "print(\"PCKMeans==========>\")\n",
    "\n",
    "K = 4#default_K if default_K>3 else K_sequence[score[\"SI\"].index(np.max(score[\"SI\"][1:]))]\n",
    "print(K)\n",
    "# 读入约束基因集，构建成对约束\n",
    "df = open(os.path.join(mldir, prefix, prefix+\".ml.txt\"),'r')\n",
    "geneslist = df.readline().split(\"\\t\")\n",
    "geneslist.pop()#去掉最后的换行符\n",
    "ml = set()\n",
    "byt = df.readlines()\n",
    "for index,value in enumerate(byt):\n",
    "    temp = value.split(\"\\t\")\n",
    "    temp.pop()#默认删除最后一个元素，并返回值\n",
    "    #temp.remove(\"\\n\")#删除元素temp\n",
    "    byt[index] = temp\n",
    "    for i in range(len(temp)):\n",
    "        for j in range(i+1, len(temp)):\n",
    "            ml.add((geneslist.index(temp[i]),geneslist.index(temp[j])))\n",
    "print(\"Number of pairwise constraints:%d\\n\" % len(ml))\n",
    "\n",
    "\n",
    "### PCKMeans聚类 ###\n",
    "\n",
    "t1 = time.time()\n",
    "pckm = PCKMeans(n_clusters=K)#, distance_type='euclidean'\n",
    "pckm.fit(np.array(X), ml=ml)#\n",
    "t2 = time.time()\n",
    "print (\"the time of clustering is %.5fs\" % (t2 - t1))\n",
    "pckm_labels = pckm.labels_\n",
    "\n",
    "\n",
    "print(\"value_counts:\\n\", pd.DataFrame(pd.value_counts(pckm_labels)).T)\n",
    "labels_counts = pd.DataFrame(pd.value_counts(pckm_labels))\n",
    "labels_counts.insert(0, \"clusters\", labels_counts.index)\n",
    "labels_counts.columns = [\"clusters\", \"counts\"]\n",
    "labels_counts.to_csv(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".PCKMeans_clustering.labels_counts.csv\"), index=False)\n",
    "pd.DataFrame(np.array([X.index, pckm_labels]).T, columns=[\"gene\", \"labels\"]).to_csv(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".PCKMeans_clustering.cluster_labels.csv\"), index=False)#, header=None\n",
    "        \n",
    "\n",
    "unique_labels = np.unique(pckm_labels)\n",
    "n_clusters_ =len(np.unique(pckm_labels)) - (1 if -1 in pckm_labels else 0)\n",
    "\n",
    "#每个模块的基因数条形图\n",
    "width = 0.35# 柱子的宽度\n",
    "# plt.clf() # 使用 plt.clf() 清理掉 axes\n",
    "fig = plt.figure(figsize=(6, 6), dpi=200)# 创建画布, 并设置分辨率为 80像素/每英寸\n",
    "plt.subplot(111)# 创建一个子图\n",
    "plt.title(\"Number of genes in the module\", fontsize=18)\n",
    "plt.xlabel(\"Module\", fontsize=16)\n",
    "plt.ylabel(\"Number of genes\", fontsize=16)\n",
    "plt.bar(labels_counts.loc[:, \"clusters\"], labels_counts.loc[:, \"counts\"], width = width, color=\"#87CEFA\") # 绘制柱状图, 每根柱子的颜色为紫罗兰色\n",
    "fig.savefig(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".Number of genes in the module.png\")\n",
    "            , bbox_inches='tight', dpi=1080)  # 保存图片，如果不设置 bbox_inches='tight'，保存的图片有可能显示不全\n",
    "fig.savefig(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".Number of genes in the module.pdf\")\n",
    "            , bbox_inches='tight')  # 保存图片，如果不设置 bbox_inches='tight'，保存的图片有可能显示不全\n",
    "pd.DataFrame.from_dict({\"clusters\":labels_counts.loc[:, \"clusters\"]\n",
    "                        , \"counts\":labels_counts.loc[:, \"counts\"]\n",
    "                       }).to_csv(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".Number of genes in the module.csv\")\n",
    "                                                                           , index=False, sep=',')\n",
    "\n",
    "plt.close()\n",
    "\n",
    "#模块内平均连通性\n",
    "values = []\n",
    "for k in np.sort(np.unique(pckm_labels)):      \n",
    "    values.append(sum(Connectivity.loc[pckm_labels==k, pckm_labels==k].sum())/sum(pckm_labels==k))\n",
    "width = 0.35# 柱子的宽度\n",
    "fig = plt.figure(figsize=(6, 6), dpi=200)# 创建画布, 并设置分辨率为 80像素/每英寸\n",
    "# plt.clf() # 使用 plt.clf() 清理掉 axes\n",
    "plt.subplot(111)# 创建一个子图\n",
    "plt.title(\"Mean Connectivity of module\", fontsize=18)\n",
    "plt.xlabel(\"Module\", fontsize=16)\n",
    "plt.ylabel(\"Mean Connectivity\", fontsize=16)\n",
    "plt.bar(np.sort(np.unique(pckm_labels)), values, width = width, color=\"#87CEFA\") # 绘制柱状图, 每根柱子的颜色为紫罗兰色ind-width/2\n",
    "fig.savefig(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".Mean_Connectivity_of_module.png\")\n",
    "            , bbox_inches='tight', dpi=1080)\n",
    "fig.savefig(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".Mean_Connectivity_of_module.pdf\")\n",
    "            , bbox_inches='tight')\n",
    "pd.DataFrame.from_dict({'pckm_labels':np.sort(np.unique(pckm_labels))\n",
    "                        , 'values':values}).to_csv(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".Mean_Connectivity_of_module.csv\")\n",
    "                                                   , index=False, sep=',')\n",
    "plt.close()\n",
    "\n",
    "#模块密度\n",
    "values = []\n",
    "for k in np.sort(np.unique(pckm_labels)):      \n",
    "    values.append(sum(Connectivity.loc[pckm_labels==k, pckm_labels==k].sum())/(sum(pckm_labels==k)*(sum(pckm_labels==k)-1)))\n",
    "assess['pckmeans']['module_density_max'] = max(values)\n",
    "width = 0.35# 柱子的宽度\n",
    "fig = plt.figure(figsize=(6, 6), dpi=200)# 创建画布, 并设置分辨率为 80像素/每英寸\n",
    "# plt.clf() # 使用 plt.clf() 清理掉 axes\n",
    "plt.subplot(111)# 创建一个子图\n",
    "plt.title(\"Density of module\", fontsize=18)\n",
    "plt.xlabel(\"Module\", fontsize=16)\n",
    "plt.ylabel(\"Density\", fontsize=16)\n",
    "plt.bar(np.sort(np.unique(pckm_labels)), values, width = width, color=\"#87CEFA\") # 绘制柱状图, 每根柱子的颜色为紫罗兰色ind-width/2\n",
    "\n",
    "fig.savefig(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".density_of_module.png\"), dpi=1080, bbox_inches='tight')\n",
    "fig.savefig(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".density_of_module.pdf\"), bbox_inches='tight')\n",
    "pd.DataFrame.from_dict({'pckm_labels':np.sort(np.unique(pckm_labels))\n",
    "                        , 'values':values}).to_csv(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".density_of_module.csv\")\n",
    "                                                   , index=False, sep=',')\n",
    "plt.close()\n",
    "\n",
    "# 参数评估\n",
    "SI = silhouette_score(X, pckm_labels)\n",
    "CH = calinski_harabasz_score(X, pckm_labels)\n",
    "DBI = davies_bouldin_score(X, pckm_labels)\n",
    "assess['pckmeans'][\"SI\"] = SI\n",
    "assess['pckmeans'][\"CH\"] = CH\n",
    "assess['pckmeans'][\"DBI\"] = DBI\n",
    "print(\"For n_clusters =\", n_clusters_,\n",
    "        \"\\nThe average silhouette_score is :\", SI)\n",
    "print(\"Calinski-Harabasz Score\",  CH,\n",
    "         \"\\nDavies Bouldin score is :\", DBI)\n",
    "\n",
    "sample_silhouette_values = silhouette_samples(X, pckm_labels)\n",
    "\n",
    "# Silhouette analysis for clustering\n",
    "# plt.clf() # 使用 plt.clf() 清理掉 axes\n",
    "fig = plt.figure(figsize=(16, 6), dpi=200)# 创建画布, 并设置分辨率为 80像素/每英寸\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.set_size_inches(18, 7) \n",
    "plt.rcParams.update({'font.family': 'Times New Roman'})\n",
    "plt.rcParams.update({'font.weight': 'normal'})\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "ax1=fig.add_subplot(121)\n",
    "ax1.set_xlim([-0.1, 1])\n",
    "ax1.set_ylim([0, X.shape[0] + (n_clusters_ + 1) * 10])\n",
    "\n",
    "y_lower = 10\n",
    "for i in range(n_clusters_):\n",
    "    ith_cluster_silhouette_values = sample_silhouette_values[pckm_labels == i]\n",
    "    ith_cluster_silhouette_values.sort()\n",
    "    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "    y_upper = y_lower + size_cluster_i\n",
    "    color = cm.nipy_spectral(float(i)/n_clusters_)\n",
    "    ax1.fill_betweenx(np.arange(y_lower, y_upper)\n",
    "                     ,ith_cluster_silhouette_values\n",
    "                     ,facecolor=color\n",
    "                     ,alpha=0.7\n",
    "                     )\n",
    "    ax1.text(-0.05\n",
    "             , y_lower + 0.5 * size_cluster_i\n",
    "             , str(i))\n",
    "    y_lower = y_upper + 10\n",
    "ax1.set_title(\"The Silhouette plot for the various clusters.\", fontsize=18)\n",
    "ax1.set_xlabel(\"The Silhouette coefficient values\", fontsize=16)\n",
    "ax1.set_ylabel(\"Cluster label\", fontsize=16)\n",
    "ax1.axvline(x=SI, color=\"red\", linestyle=\"--\")\n",
    "ax1.set_yticks([])\n",
    "ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "#colors = cm.nipy_spectral(pckm_labels.astype(float) / n_clusters_)\n",
    "colors = Labels2Color(X, pckm_labels)['colorcode']\n",
    "ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "ax2.scatter3D(X_Dim[:, 0], X_Dim[:, 1],X_Dim[:, 2]\n",
    "           ,marker='o'\n",
    "           ,s=4\n",
    "           ,c=colors\n",
    "           )\n",
    "\n",
    "ax2.set_title(\"The visualization of the clustered data.\", fontsize=18)\n",
    "ax2.set_xlabel(\"Feature space for the 1st feature\", fontsize=16)\n",
    "ax2.set_ylabel(\"Feature space for the 2nd feature\", fontsize=16, rotation=38) #, rotation=38 y 轴名称旋转 38 度\n",
    "ax2.set_zlabel('Z')\n",
    "plt.suptitle((\"Silhouette analysis for ScC-WGCNA clustering on %s data with n_clusters = %d\" % (prefix, n_clusters_)),\n",
    "             fontsize=20, fontweight='bold')\n",
    "fig = plt.gcf()\n",
    "fig.savefig(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".Silhouette analysis for ScC-WGCNA clustering on %s data.png\" % prefix)\n",
    "            , bbox_inches='tight', dpi=1080)  # 保存图片，如果不设置 bbox_inches='tight'，保存的图片有可能显示不全\n",
    "fig.savefig(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".Silhouette analysis for ScC-WGCNA clustering on %s data.pdf\" % prefix)\n",
    "            , bbox_inches='tight')  # 保存图片，如果不设置 bbox_inches='tight'，保存的图片有可能显示不全\n",
    "plt.close()\n",
    "pd.DataFrame.from_dict(assess).to_csv(os.path.join(outdir, prefix, filename.rstrip('.csv')+\".ScC-WGCNA_vs_WGCNA.assess.csv\"), sep=',',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da44db-dc34-4f28-a29b-65c0a45b2b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "### The visualization of the clustered data ###\n",
    "###########################################################\n",
    "\n",
    "plt.clf() # 使用 plt.clf() 清理掉 axes\n",
    "# set up a figure twice as wide as it is tall\n",
    "fig = plt.figure(figsize=(16, 6), dpi=200)# 创建画布, 并设置分辨率为 80像素/每英寸\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.set_size_inches(18, 7) \n",
    "plt.rcParams.update({'font.family': 'Times New Roman'})\n",
    "plt.rcParams.update({'font.weight': 'normal'})\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "colors1 = Labels2Color(X, wgcna_labels)['colorcode']\n",
    "# set up the axes for the first plot\n",
    "ax1.axis('off')\n",
    "ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "ax1.scatter3D(X_Dim[:, 0], X_Dim[:, 1], X_Dim[:, 2]\n",
    "           ,marker='o'\n",
    "           ,s=4\n",
    "           ,c=colors1\n",
    "           )\n",
    "ax1.set_title(\"WGCNA with n_clusters = %d\" % WGCNA_K, fontsize=18)\n",
    "ax1.set_xlabel(\"Feature space for the 1st feature\", fontsize=16)\n",
    "ax1.set_ylabel(\"Feature space for the 2nd feature\", fontsize=16)\n",
    "ax1.set_zlabel(\"z\", fontsize=16)\n",
    "\n",
    "# ax1.spines['top'].set_visible(False)\n",
    "# ax1.spines['right'].set_visible(False)\n",
    "# ax1.spines['bottom'].set_visible(False)\n",
    "# ax1.spines['left'].set_visible(False)\n",
    "\n",
    "colors2 = Labels2Color(X, pckm_labels)['colorcode']\n",
    "# set up the axes for the first plot\n",
    "ax2.axis('off')\n",
    "ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "\n",
    "ax2.scatter3D(X_Dim[:, 0], X_Dim[:, 1], X_Dim[:, 2]\n",
    "           ,marker='o'\n",
    "           ,s=4\n",
    "           ,c=colors2\n",
    "           )\n",
    "ax2.set_title(\"PCKMeans with n_clusters = %d\" % K, fontsize=18)\n",
    "ax2.set_xlabel(\"Feature space for the 1st feature\", fontsize=16)\n",
    "ax2.set_ylabel(\"Feature space for the 2nd feature\", fontsize=16)\n",
    "ax2.set_zlabel(\"z\", fontsize=16)\n",
    "# ax2.spines['top'].set_visible(False)\n",
    "# ax2.spines['right'].set_visible(False)\n",
    "# ax2.spines['bottom'].set_visible(False)\n",
    "# ax2.spines['left'].set_visible(False)\n",
    "plt.suptitle((\"The visualization of %s data clustering results\" % prefix),\n",
    "             fontsize=20, fontweight='bold')\n",
    "fig = plt.gcf()\n",
    "\n",
    "fig.savefig(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".the visualization of %s data with WGCNA and ScC-WGCNA clustering results.png\" % prefix)\n",
    "            , bbox_inches='tight', dpi=1080)\n",
    "fig.savefig(os.path.join(outdir, prefix, filename.rstrip('csv')+distance+\".the visualization of %s data with WGCNA and ScC-WGCNA clustering results.pdf\" % prefix)\n",
    "            , bbox_inches='tight')\n",
    "# plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838f1daa-05a4-4506-a3a7-80af06c7920c",
   "metadata": {},
   "source": [
    "### summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6e73db-ce06-4b16-8178-781744008187",
   "metadata": {},
   "outputs": [],
   "source": [
    "mldir = \"E:/Project/Project001 WGCNA/main/step-6-FactorAnalyzer/outdir\"\n",
    "data_indir = \"E:/Project/Project001 WGCNA/main/step-3-FeatureSelection/outdir\"\n",
    "labelsdir = \"E:/Project/Project001 WGCNA/main/step-4-wgcna/outdir\"\n",
    "out_dir = \"E:/Project/Project001 WGCNA/main/step-7-clustering/semi_supervised Kmeans/outdir\"\n",
    "dcorr_dir = \"E:/Project/Project001 WGCNA/main/step-7-clustering/Calculate the correlation coefficient/outdir\"\n",
    "\n",
    "distance = \"dcorr\" #\"pearson\" #\n",
    "\n",
    "filename = '.tcga_gtex.tpm.updown.feature_selection.csv'\n",
    "# filename = '.tumor.tpm.updown.feature_selection.csv'\n",
    "prefix = filename.split('.')[0]\n",
    "\n",
    "mldir = '/'.join([mldir, filename.split('.')[1]])\n",
    "labelsdir = '/'.join([labelsdir, filename.split('.')[1]])\n",
    "# outdir = os.path.join(outdir, filename.split('.'))\n",
    "outdir = '/'.join([out_dir, filename.split('.')[1], distance])\n",
    "dcorr_dir = '/'.join([dcorr_dir, filename.split('.')[1]])\n",
    "\n",
    "if not os.path.exists(os.path.join(outdir, prefix)):\n",
    "    os.makedirs(os.path.join(outdir, prefix))\n",
    "    \n",
    "\n",
    "cancer_names = [\"BLCA\", \"BRCA\", \"COAD\", \"KIRC\", \"LUAD\", \"LUSC\", \"STAD\",  \"PAAD\"]#\n",
    "distance_metrics = [\"euclidean\", \"snn\", \"dcorr\", \"pearson\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e76facb-4c4e-4f51-9429-6b496bcd0d5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################\n",
    "####### summary  #######\n",
    "########################\n",
    "\n",
    "assess = dict(wgcna = dict(SI = {}, CH = {}, DBI = {}, module_density_max = {})\n",
    "              , pckmeans = dict(SI = {}, CH = {}, DBI = {}, module_density_max = {}))\n",
    "   \n",
    "\n",
    "for cancer in cancer_names:\n",
    "    prefix = cancer\n",
    "    temp = pd.read_csv(os.path.join(outdir, prefix, prefix+filename.rstrip('.csv')+\".ScC-WGCNA_vs_WGCNA.assess.csv\"), sep=',', index_col=0)\n",
    "    temp.to_dict()\n",
    "    for key1 in ['wgcna', 'pckmeans']:\n",
    "        for key2 in ['SI', 'CH', 'DBI', 'module_density_max']:\n",
    "            assess[key1][key2][cancer] = temp[key1][key2]\n",
    "\n",
    "module_density_max = {}\n",
    "module_density_max['WGCNA'] = assess['wgcna']['module_density_max']\n",
    "module_density_max['ScC-WGCNA'] = assess['pckmeans']['module_density_max']\n",
    "moduleDensity_max = round(pd.DataFrame.from_dict(module_density_max, orient= 'index'), 4)\n",
    "moduleDensity_max.to_csv(os.path.join(outdir, distance+\".module_density_max.csv\"), index=True)\n",
    "\n",
    "\n",
    "ml_summary = {'Number of gene':{}, 'Number of gene pair':{}, 'Number of constrained gene':{}}\n",
    "for cancer in cancer_names:\n",
    "    prefix = cancer\n",
    "    # 读入约束基因集，构建成对约束\n",
    "    df = open(os.path.join(mldir, prefix, prefix+\".ml.txt\"),'r')\n",
    "    geneslist = df.readline().split(\"\\t\")\n",
    "    geneslist.pop()#去掉最后的换行符\n",
    "    ml_summary['Number of gene'][prefix] = len(geneslist)\n",
    "    \n",
    "    ml = set()\n",
    "    byt = df.readlines()\n",
    "    for index,value in enumerate(byt):\n",
    "        temp = value.split(\"\\t\")\n",
    "        temp.pop()#默认删除最后一个元素，并返回值\n",
    "        #temp.remove(\"\\n\")#删除元素temp\n",
    "        byt[index] = temp\n",
    "        for i in range(len(temp)):\n",
    "            for j in range(i+1, len(temp)):\n",
    "                ml.add((geneslist.index(temp[i]),geneslist.index(temp[j])))\n",
    "    ml_summary['Number of gene pair'][prefix] = len(ml)\n",
    "    print(\"Number of pairwise constraints:%d\\n\" % len(ml))\n",
    "    \n",
    "    temp = []\n",
    "    for u,v in ml:\n",
    "        temp += [u,v]\n",
    "    ml_summary['Number of constrained gene'][prefix] = round(len(set(temp))/len(geneslist), 4)\n",
    "    print(\"Number of constrained gene:%d\\n\" % len(set(temp)))\n",
    "\n",
    "pd.DataFrame.from_dict(ml_summary, orient= 'index').to_csv(os.path.join(outdir, distance+\".summary of pairwise constraints.csv\"), index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcf020a-4075-4f0b-b9fe-a3c1f25d5218",
   "metadata": {},
   "source": [
    "### The visualization of the  evaluation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f01de51-c1a6-4ce1-baa5-1ac81b40b373",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "### The visualization of the  evaluation score  ###\n",
    "###########################################################\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "fig.set_size_inches(24, 8)\n",
    "# plt.rcParams['xtick.labelsize']=12\n",
    "# plt.rcParams['ytick.labelsize']=12\n",
    "\n",
    "x = cancer_names #range(len(score_wgcna[\"SI\"]))# \n",
    "ax1.plot(assess['wgcna'][\"SI\"].keys(), assess['wgcna'][\"SI\"].values(), color = 'red'\n",
    "         , linewidth = 1.0, linestyle = '-', label='WGCNA', marker='d', markerfacecolor='red', markersize=10)\n",
    "ax1.plot(assess['pckmeans'][\"SI\"].keys(), assess['pckmeans'][\"SI\"].values(), color = 'green'\n",
    "         , linewidth = 1.0, linestyle = '--', label='ScC-WGCNA', marker='^', markerfacecolor='green', markersize=10)\n",
    "ax1.set_xlabel('datasets', fontdict={'size': 16})\n",
    "ax1.set_ylabel('Silhouette Coefficient Score', fontdict={'size': 16})\n",
    "ax1.set_title(\"SI\", fontdict={'size': 18})\n",
    "ax1.legend(loc='best', fontsize = 12)\n",
    "ax1.set_xticklabels(assess['wgcna'][\"SI\"].keys(), rotation = 30, fontsize = 12)\n",
    "plt.setp(ax1.get_yticklabels(), fontsize=12)\n",
    "\n",
    "ax2.plot(assess['wgcna'][\"CH\"].keys(), assess['wgcna'][\"CH\"].values(), color = 'red'\n",
    "         , linewidth = 1.0, linestyle = '-', label='WGCNA', marker='d', markerfacecolor='red', markersize=10)\n",
    "ax2.plot(assess['pckmeans'][\"CH\"].keys(), assess['pckmeans'][\"CH\"].values(), color = 'green'\n",
    "         , linewidth = 1.0, linestyle = '--', label='ScC-WGCNA', marker='^', markerfacecolor='green', markersize=10)\n",
    "ax2.set_xlabel('datasets', fontdict={'size': 16})\n",
    "ax2.set_ylabel('Calinski Harabasz Score', fontdict={'size': 16})\n",
    "ax2.set_title(\"CH\", fontdict={'size': 18})\n",
    "ax2.legend(loc='best', fontsize = 12)\n",
    "ax2.set_xticklabels(assess['wgcna'][\"CH\"].keys(), rotation = 30, fontsize = 12)\n",
    "plt.setp(ax2.get_yticklabels(), fontsize=12)\n",
    "\n",
    "ax3.plot(assess['wgcna'][\"DBI\"].keys(), assess['wgcna'][\"DBI\"].values(), color = 'red'\n",
    "         , linewidth = 1.0, linestyle = '-', label='WGCNA', marker='d', markerfacecolor='red', markersize=10)\n",
    "ax3.plot(assess['pckmeans'][\"DBI\"].keys(), assess['pckmeans'][\"DBI\"].values(), color = 'green'\n",
    "         , linewidth = 1.0, linestyle = '--', label='ScC-WGCNA', marker='^', markerfacecolor='green', markersize=10)\n",
    "ax3.set_xlabel('datasets', fontdict={'size': 16})\n",
    "ax3.set_ylabel('Davies Bouldin Score', fontdict={'size': 16})\n",
    "ax3.set_title(\"DBI\", fontdict={'size': 18})\n",
    "ax3.legend(loc='best', fontsize = 12)\n",
    "ax3.set_xticklabels(assess['wgcna'][\"DBI\"].keys(), rotation = 30, fontsize = 12)\n",
    "plt.setp(ax3.get_yticklabels(), fontsize=12)\n",
    "\n",
    "plt.suptitle((\"SI,CH and DBI scores for WGCNA and ScC-WGCNA clustering on sample data\"), fontsize=20, fontweight='bold')\n",
    "fig = plt.gcf()\n",
    "fig.savefig(os.path.join(outdir, distance+\".SI,CH and DBI scores for WGCNA and ScC-WGCNA clustering on sample data.png\")\n",
    "            , bbox_inches='tight', dpi=1080)\n",
    "fig.savefig(os.path.join(outdir, distance+\".SI,CH and DBI scores for WGCNA and ScC-WGCNA clustering on sample data.pdf\"), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a353c5f4-1397-4184-8cad-5d17a08f0b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2356027f-737d-4b86-9f01-4571dd17cc21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95328695-6455-4020-8f53-1923fd5c9894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec7e29e-15ce-4480-bae3-c00fd5641885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c246dc88-0543-4148-98e6-ed5f812da284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76facbbc-c098-481a-b207-ea0326257ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c643053-e78e-4a1f-b6e2-b35d28ca186f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1e8e21-fde9-4eec-9a2a-b2a24c4899f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "# 这两行代码解决 plt 中文显示的问题\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score, calinski_harabasz_score # CH 指标，DBI \n",
    "from sklearn.metrics import silhouette_samples, silhouette_score # 轮廓系数\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.spatial.distance import cdist#cdist(XA, XB, 'correlation')\n",
    "from dcor import distance_correlation as dcorr\n",
    "from scipy.stats import pearsonr\n",
    "#    1）输入：x为特征，y为目标变量.\n",
    "#    2）输出：r： 相关系数 [-1，1]之间，p-value: p值。\n",
    "#         注： p值越小，表示相关系数越显著，一般p值在500个样本以上时有较高的可靠性。\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from matplotlib.axes._axes import _log as matplotlib_axes_logger\n",
    "matplotlib_axes_logger.setLevel('ERROR')#日志只显示error级别的错误\n",
    "\n",
    "from pckmeans import PCKMeans\n",
    "from mpckmeans import MPCKMeans\n",
    "\n",
    "##my\n",
    "from labels2color import Labels2Color\n",
    "#from topological_overlap_measure import TOMsimilarity\n",
    "from topological_overlap_measure import *\n",
    "#from soothsayer.networks import topological_overlap_measure\n",
    "\n",
    "from my_functions import *\n",
    "\n",
    "\n",
    "mldir = \"E:/Project/Project001 WGCNA/main/step-6-FactorAnalyzer/outdir/\"\n",
    "data_indir = \"E:/Project/Project001 WGCNA/main/step-3-FeatureSelection/outdir/\"\n",
    "labelsdir = \"E:/Project/Project001 WGCNA/main/step-4-wgcna/outdir/\"\n",
    "out_dir = \"E:/Project/Project001 WGCNA/main/step-7-clustering/semi_supervised Kmeans/outdir/\"\n",
    "dcorr_dir = \"E:/Project/Project001 WGCNA/main/step-7-clustering/semi_supervised Kmeans/data/dcorr/\"\n",
    "\n",
    "cancer_names = [\"BLCA\", \"BRCA\", \"COAD\", \"KIRC\", \"LUAD\", \"LUSC\", \"STAD\",  \"PAAD\"]#\n",
    "distance_metrics = [\"euclidean\", \"snn\", \"dcorr\", \"pearson\"]\n",
    "\n",
    "score_wgcna = dict(SI = [], CH = [], DBI = [])\n",
    "score_pckmeans = dict(SI = [], CH = [], DBI = [])\n",
    "#score_kmeans = dict(SI = [], CH = [], DBI = [])\n",
    "\n",
    "distance = \"dcorr\" #\"pearson\" # \n",
    "outdir = out_dir+distance+\"/\"\n",
    "\n",
    "powers = {}\n",
    "# if distance==\"dcorr\":\n",
    "#     powers = {\"KIRC\": 3, \"LIHC\": 3, \"LUSC\": 3, \"OV\": 3, \"PAAD\":3, \"STAD\": 3}\n",
    "# elif distance==\"pearson\":\n",
    "#     powers = {\"KIRC\": 3, \"LIHC\": 4, \"LUSC\": 3, \"OV\": 2, \"PAAD\":3, \"STAD\": 7}\n",
    "# else:\n",
    "#     powers = {\"KIRC\": 6, \"LIHC\": 6, \"LUSC\": 6, \"OV\": 6, \"PAAD\":6, \"STAD\": 6}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460a2216-3381-429a-baba-24c634034e12",
   "metadata": {},
   "source": [
    "### 调用R script计算软阈值power\n",
    "\n",
    "</br>\n",
    "def pickSoftThreshold(data, power=20, dataIsExpr=False, prefix=\"01\", outdir=\".\", verbose = 5):</br>\n",
    "    #=====================</br>\n",
    "    #function 调用R script计算软阈值power</br>\n",
    "    #=====================</br>\n",
    "    import rpy2.robjects as robjects  # 导入R对象</br>\n",
    "    from rpy2.robjects import pandas2ri</br>\n",
    "    pandas2ri.activate()</br>\n",
    "    #加载R包和R函数</br>\n",
    "    robjects.r[\"source\"]('D:\\\\xiaogy\\\\WGCNA.main\\\\step-7-clustering\\\\semi_supervised Kmeans\\\\step-7-0-pickSoftThreshold.R')</br>\n",
    "    powers = robjects.IntVector(list(range(1, power+1)))</br>\n",
    "    similarExpr = robjects.r['data.matrix'](data) #把data转变成矩阵 </br>\n",
    "    sft = robjects.r['pickSoftThreshold'](similarExpr, dataIsExpr = dataIsExpr, powerVector = powers, prefix=prefix, outdir=outdir, verbose =verbose)#</br>\n",
    "    sft = {\"powerEstimate\": sft.rx2(\"powerEstimate\")[0], \"fitIndices\": pd.DataFrame(sft.rx2(\"fitIndices\"), index=sft.rx2(\"fitIndices\").names).T}</br>\n",
    "    return(sft)</br>\n",
    "</br>\n",
    "\n",
    "prefix =  \"KIRC\"</br>\n",
    "distance = \"dcorr\"</br>\n",
    "sim = pd.read_csv(dcorr_dir+prefix+\"/\"+prefix+\".TPM.updown.feature_selection.dcorr.csv\", sep=',')</br>\n",
    "sim.index = sim.columns</br>\n",
    "\n",
    "power = 20</br>\n",
    "sft = pickSoftThreshold(sim, power=power, prefix=prefix, outdir=outdir)</br>\n",
    "#print(sft)<\\br>\n",
    "powers[prefix] = sft[\"powerEstimate\"]</br>\n",
    "sft[\"fitIndices\"].to_csv(outdir+prefix+\"/\"+prefix+\".\"+\"sft_fitIndices.csv\", index=False, sep=',')</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532090d1-ac2d-41c9-9960-deed0fcf1e9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 画n个癌症的聚类K值的学习曲线选取最佳K ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0740d1-fcd6-4d12-8aa8-28090bd81b81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### 画n个癌症的聚类K值的学习曲线选取最佳K ###\n",
    "#先运算所有dataset再对学习曲线可视化\n",
    "\n",
    "score_wgcna = dict(SI = {}, CH = {}, DBI = {})\n",
    "score_pckmeans = dict(SI = {}, CH = {}, DBI = {})\n",
    "#score_kmeans = dict(SI = {}, CH = {}, DBI = {})\n",
    "xticks = {}\n",
    "WGCNA_k = {}\n",
    "default_K = {}\n",
    "'''\n",
    "K_sequence = {\"LUSC\": c(3, 4, 5)\n",
    "              , \"KIRC\": c(3, 4, 5, 6, 7, 8)\n",
    "              , \"LIHC\": range(math.floor(wgcna_k*0.4), math.ceil(wgcna_k*1.2), 1)\n",
    "              , \"STAD\": 6\n",
    "              , \"OV\": 3\n",
    "              , \"PAAD\":5\n",
    "             }\n",
    "'''\n",
    "# for prefix_index, prefix in enumerate(cancer_names):\n",
    "\n",
    "\n",
    "\n",
    "for prefix_index, prefix in enumerate(cancer_names):\n",
    "    prefix = prefix   \n",
    "    print(\"###==================== %s ====================###\\n\" % prefix)\n",
    "\n",
    "    \n",
    "    if not os.path.exists(outdir+prefix):\n",
    "        os.makedirs(outdir+prefix)\n",
    "        \n",
    "    try:\n",
    "        \n",
    "        data = pd.read_csv(data_indir+prefix+\"/\"+prefix+\".tumor.tpm.updown.feature_selection.csv\", sep=',', index_col=0)\n",
    "        print(\"Input: data.shape\", data.shape)\n",
    "        print(\"NAN check for data: \", data.isnull().values.sum())\n",
    "\n",
    "        if distance==\"pearson\":\n",
    "            sim = data.T.corr()#dcor## # 计算相关系数，得到一个矩阵\n",
    "        elif distance==\"snn\":   \n",
    "            snn_sim = snn_sim_matrix(data, k=5)\n",
    "        elif distance==\"dcorr\":\n",
    "            sim = pd.read_csv(dcorr_dir+prefix+\"/\"+prefix+\".tumor.tpm.updown.feature_selection.dcorr.csv\", sep=',')\n",
    "            sim.index = sim.columns\n",
    "        else:\n",
    "            print(\"input parameter error：Undefined distance type.\")\n",
    "\n",
    "        print(\"NAN check: \", sim.isnull().values.sum())\n",
    "        #先删除全是空值的行和列\n",
    "        if sim.isnull().values.ravel().sum():\n",
    "            sim.drop(sim.columns[sim.isnull().all(axis=1)].tolist(), inplace=True)#删除全是NAN的行\n",
    "            sim = sim[sim.columns[~sim.isnull().all(axis=0)].tolist()]#删除全是NAN的列\n",
    "            #再用0填充NAN\n",
    "            sim.fillna(0, inplace=True)#用0填补缺失值\n",
    "        print(\"After processing NA: sim.shape\", sim.shape)\n",
    "        sim.to_csv(outdir+prefix+\"/\"+prefix+\".\"+distance+\".sim.csv\", index=False, sep=',')\n",
    "        \n",
    "        \n",
    "        # 调用R script计算软阈值\n",
    "        power = 20\n",
    "        sft = pickSoftThreshold(sim, power=power, prefix=prefix, outdir=outdir)\n",
    "        #print(sft)\n",
    "        powers[prefix] = sft[\"powerEstimate\"]\n",
    "        sft[\"fitIndices\"].to_csv(outdir+prefix+\"/\"+prefix+\".\"+\"sft_fitIndices.csv\", index=False, sep=',')\n",
    "\n",
    "        \n",
    "        #Check scale free topology\n",
    "        # Create an adjacency network； ^6 近似无标度化\n",
    "        # here we define the adjacency matrix using soft thresholding with beta=6\n",
    "        ADJ = abs(sim)**powers[prefix] # 近似无标度化\n",
    "        print(\"Input: ADJ\", \"Max: {}\".format(ADJ.values.ravel().max()), \"Min: {}\".format(ADJ.values.ravel().min()), sep=\"\\n\")\n",
    "        print(\"NAN check: \", ADJ.isnull().values.sum())\n",
    "        ADJ.to_csv(outdir+prefix+\"/\"+prefix+\".\"+distance+\".ADJ.csv\", index=False, sep=',')\n",
    "      \n",
    "        # Compute topological overlap\n",
    "        #from topological_overlap_measure import TOMsimilarity\n",
    "        from topological_overlap_measure import *\n",
    "        #from soothsayer.networks import topological_overlap_measure\n",
    "        TOM = TOMsimilarity(ADJ)#把邻接矩阵转换为拓扑重叠矩阵topological_overlap_measure\n",
    "        dissTOM = 1 - TOM\n",
    "\n",
    "        TOM.to_csv(outdir+prefix+\"/\"+prefix+\".\"+distance+\".TOM.csv\", index=False, sep=',')\n",
    "        dissTOM.to_csv(outdir+prefix+\"/\"+prefix+\".\"+distance+\".dissTOM.csv\", index=False, sep=',')\n",
    "        '''\n",
    "        dissTOM = pd.read_csv(outdir+prefix+\"/\"+prefix+\".\"+distance+\".dissTOM.csv\", sep=',')\n",
    "        dissTOM.index = dissTOM.columns\n",
    "        '''\n",
    "        X = dissTOM\n",
    "        \n",
    "               \n",
    "        df = open(mldir+prefix+\"/\"+prefix+\".ml.txt\",'r')\n",
    "        geneslist = df.readline().split(\"\\t\")\n",
    "        geneslist.pop()#去掉最后的换行符\n",
    "        ml = set()\n",
    "        byt = df.readlines()\n",
    "        for index,value in enumerate(byt):\n",
    "            temp = value.split(\"\\t\")\n",
    "            temp.pop()#默认删除最后一个元素，并返回值\n",
    "            #temp.remove(\"\\n\")#删除元素temp\n",
    "            byt[index] = temp\n",
    "            for i in range(len(temp)):\n",
    "                for j in range(i+1, len(temp)):\n",
    "                    ml.add((geneslist.index(temp[i]),geneslist.index(temp[j])))\n",
    "        print(\"Constraints in pairs gene number:%d\" % len(ml))\n",
    "        \n",
    "        \n",
    "        ### 可视化WGCNA聚类结果作为参考 ###\n",
    "        \n",
    "        wgcna_y_pred = pd.read_csv(labelsdir+prefix+\"/\"+prefix+\".wgcna.result.csv\", index_col=False)\n",
    "        wgcna_y_pred.index = wgcna_y_pred[\"gene\"].values\n",
    "        wgcna_y_pred = wgcna_y_pred.loc[X.index]\n",
    "        wgcna_labels = wgcna_y_pred[\"dynamicMods\"].values\n",
    "        #print(\"value_counts:\\n\", pd.DataFrame(pd.value_counts(wgcna_labels)).T)\n",
    "        ##分类个数：lables中包含-1，表示噪声点\n",
    "        n_clusters_ =len(np.unique(wgcna_labels)) - (1 if -1 in wgcna_labels else 0) \n",
    "        print(\"Number of clusters with WGCNA:%d\" % n_clusters_)\n",
    "        wgcna_k = n_clusters_\n",
    "        WGCNA_k[prefix] = n_clusters_\n",
    "        SI = silhouette_score(X, wgcna_labels)\n",
    "        CH = calinski_harabasz_score(X, wgcna_labels)\n",
    "        DBI = davies_bouldin_score(X, wgcna_labels)\n",
    "        score_wgcna[\"SI\"][prefix] = SI\n",
    "        score_wgcna[\"CH\"][prefix] = CH\n",
    "        score_wgcna[\"DBI\"][prefix] = DBI\n",
    "        #print(\"For n_clusters =\", n_clusters_, \"\\nThe average silhouette_score is :\", SI)\n",
    "        #print(\"Calinski-Harabasz Score\",  CH, \"\\nDavies Bouldin score is :\", DBI)\n",
    "        \n",
    "        ################################################\n",
    "        score_pckmeans[\"SI\"][prefix] = []\n",
    "        score_pckmeans[\"CH\"][prefix] = []\n",
    "        score_pckmeans[\"DBI\"][prefix] = []\n",
    "        '''\n",
    "        score_kmeans[\"SI\"][prefix] = []\n",
    "        score_kmeans[\"CH\"][prefix] = []\n",
    "        score_kmeans[\"DBI\"][prefix] = []\n",
    "        '''\n",
    "        K_sequence = range(math.floor(wgcna_k*0.4), math.ceil(wgcna_k*1.2), 1) #range(6, 11, 1)\n",
    "        for k in K_sequence:\n",
    "            print(\"    K = \", k)\n",
    "            try:\n",
    "                ### 测试PCKMeans聚类效果 ###\n",
    "                t1 = time.time()\n",
    "                pckm = PCKMeans(n_clusters=k) #, distance_type='euclidean'\n",
    "                pckm.fit(np.array(X), ml=ml)\n",
    "                t2 = time.time()\n",
    "                #print (\"the time of clustering is %.5fs\" % (t2 - t1))\n",
    "                pckm_labels = pckm.labels_ \n",
    "                #print(\"value_counts:\\n\", pd.DataFrame(pd.value_counts(pckm_labels)).T)     \n",
    "                n_clusters_ =len(np.unique(pckm_labels)) - (1 if -1 in pckm_labels else 0)\n",
    "                #pd.DataFrame(pckm_labels, index=X.index).to_csv(outdir+prefix+\"/\"+prefix+\".PCKMeans_clustering\"+\".cluster_labels.k%d.csv\" % n_clusters_, header=None, index=True)\n",
    "\n",
    "                SI = silhouette_score(X, pckm_labels)\n",
    "                CH = calinski_harabasz_score(X, pckm_labels)\n",
    "                DBI = davies_bouldin_score(X, pckm_labels)\n",
    "                score_pckmeans[\"SI\"][prefix].append(SI)\n",
    "                score_pckmeans[\"CH\"][prefix].append(CH)\n",
    "                score_pckmeans[\"DBI\"][prefix].append(DBI)\n",
    "                #print(\"For n_clusters =\", n_clusters_, \"\\nThe average silhouette_score is :\", SI)\n",
    "                #print(\"Calinski-Harabasz Score\",  CH, \"\\nDavies Bouldin score is :\", DBI)\n",
    "\n",
    "                '''\n",
    "                ### 测试KMeans聚类效果 ###\n",
    "                #from sklearn.cluster import KMeans\n",
    "\n",
    "                t1 = time.time()\n",
    "                km = KMeans(n_clusters=k)\n",
    "                km.fit(X)\n",
    "                t2 = time.time()\n",
    "                #print (\"the time of clustering is %.5fs\" % (t2 - t1))\n",
    "                km_labels = km.labels_\n",
    "                #print(\"value_counts:\\n\", pd.DataFrame(pd.value_counts(km_labels)).T)        \n",
    "                n_clusters_ =len(np.unique(km_labels)) - (1 if -1 in km_labels else 0)\n",
    "                #pd.DataFrame(km_labels, index=X.index).to_csv(outdir+prefix+\"/\"+prefix+\".KMeans_clustering\"+\".cluster_labels.k%d.csv\" % n_clusters_, header=None, index=True)\n",
    "\n",
    "                SI = silhouette_score(X, km_labels)\n",
    "                CH = calinski_harabasz_score(X, km_labels)\n",
    "                DBI = davies_bouldin_score(X, km_labels)\n",
    "                score_kmeans[\"SI\"][prefix_index].append(SI)\n",
    "                score_kmeans[\"CH\"][prefix_index].append(CH)\n",
    "                score_kmeans[\"DBI\"][prefix_index].append(DBI)\n",
    "                #print(\"For n_clusters =\", n_clusters_, \"\\nThe average silhouette_score is :\", SI)\n",
    "                #print(\"Calinski-Harabasz Score\",  CH, \"\\nDavies Bouldin score is :\", DBI)\n",
    "                '''\n",
    "            except Exception as e:\n",
    "                print(\"\\n==============================\")\n",
    "                print(\"    Error processing %s\" % k)\n",
    "                print(\"    \", e)\n",
    "                score_pckmeans[\"SI\"][prefix].append(0)\n",
    "                score_pckmeans[\"CH\"][prefix].append(0)\n",
    "                score_pckmeans[\"DBI\"][prefix].append(0)\n",
    "                '''\n",
    "                score_kmeans[\"SI\"][prefix_index].append(0)\n",
    "                score_kmeans[\"CH\"][prefix_index].append(0)\n",
    "                score_kmeans[\"DBI\"][prefix_index].append(0)\n",
    "                '''\n",
    "                print(\"==============================\\n\")\n",
    "                continue\n",
    "        default_K[prefix] = xticks[prefix][score_pckmeans[\"SI\"][prefix_index].index(np.max(score_pckmeans[\"SI\"][prefix_index]))]\n",
    "        xticks[prefix] = K_sequence\n",
    " \n",
    "        pd.DataFrame.from_dict({'xticks':xticks[prefix] + [WGCNA_k[prefix]]\n",
    "                        ,'SI':score_pckmeans[\"SI\"][prefix] + [score_wgcna[\"SI\"][prefix]]\n",
    "                        ,\"CH\":score_pckmeans[\"CH\"][prefix] + [score_wgcna[\"CH\"][prefix]]\n",
    "                        ,\"DBI\":score_pckmeans[\"DBI\"][prefix] + [score_wgcna[\"DBI\"][prefix]]}\n",
    "                       ).to_csv(outdir+prefix+\"/\"+\"%s.Kvalue_learn-curve.csv\" % prefix, index=False, sep=',')\n",
    "        \n",
    "        ### The visualization of the  evaluation score  ###\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "        fig.set_size_inches(18, 6)\n",
    "\n",
    "        #xticks = range(len(score_pckmeans[\"SI\"][prefix_index]))# K_sequence #\n",
    "\n",
    "        #ax1.plot(xticks[prefix], score_wgcna[\"SI\"], color = 'red', linewidth = 1.0, linestyle = '-', label='WGCNA', marker='d', markerfacecolor='red', markersize=10)\n",
    "        ax1.plot(xticks[prefix], score_pckmeans[\"SI\"][prefix], color = 'green', linewidth = 1.0, linestyle = '--', label='ScC-WGCNA', marker='^', markerfacecolor='green', markersize=10)\n",
    "        #ax1.plot(xticks[prefix], score_kmeans[\"SI\"][prefix], color = 'blue', linewidth = 1.0, linestyle = '-.', label='KMeans', marker='o', markerfacecolor='blue', markersize=10)\n",
    "        ax1.scatter(WGCNA_k[prefix], score_wgcna[\"SI\"][prefix], s=100, c='r', marker='*',alpha=0.8)\n",
    "        ax1.set_xlabel('K', fontdict={'size': 16})\n",
    "        ax1.set_ylabel('Silhouette Coefficient Score', fontdict={'size': 16})\n",
    "        ax1.set_title(\"SI\", fontdict={'size': 18})\n",
    "        ax1.legend(loc='best')\n",
    "        #plt.yticks(range(0, 50, 5)) \n",
    "        #plt.grid(True, linestyle='--', alpha=0.5)#添加网格\n",
    "        #在对应坐标处更换名称\n",
    "        #ax1.yticks([-2,-1,0,1,2],['really bad','b','c','d','good'])\n",
    "\n",
    "        #ax2.plot(x, score_wgcna[\"CH\"], color = 'red', linewidth = 1.0, linestyle = '-', label='WGCNA', marker='d', markerfacecolor='red', markersize=10)\n",
    "        ax2.plot(xticks[prefix], score_pckmeans[\"CH\"][prefix], color = 'green', linewidth = 1.0, linestyle = '--', label='ScC-WGCNA', marker='^', markerfacecolor='green', markersize=10)\n",
    "        #ax2.plot(xticks[prefix], score_kmeans[\"CH\"][prefix], color = 'blue', linewidth = 1.0, linestyle = '-.', label='KMeans', marker='o', markerfacecolor='blue', markersize=10)\n",
    "        ax2.scatter(WGCNA_k[prefix], score_wgcna[\"CH\"][prefix], s=100, c='r', marker='*',alpha=0.8)\n",
    "        ax2.set_xlabel('K', fontdict={'size': 16})\n",
    "        ax2.set_ylabel('Calinski Harabasz Score', fontdict={'size': 16})\n",
    "        ax2.set_title(\"CH\", fontdict={'size': 18})\n",
    "        ax2.legend(loc='best')\n",
    "\n",
    "        #ax3.plot(x, score_wgcna[\"DBI\"], color = 'red', linewidth = 1.0, linestyle = '-', label='WGCNA', marker='d', markerfacecolor='red', markersize=10)\n",
    "        ax3.plot(xticks[prefix], score_pckmeans[\"DBI\"][prefix], color = 'green', linewidth = 1.0, linestyle = '--', label='ScC-WGCNA', marker='^', markerfacecolor='green', markersize=10)\n",
    "        #ax3.plot(xticks[prefix], score_kmeans[\"DBI\"][prefix], color = 'blue', linewidth = 1.0, linestyle = '-.', label='KMeans', marker='o', markerfacecolor='blue', markersize=10)\n",
    "        ax3.scatter(WGCNA_k[prefix], score_wgcna[\"DBI\"][prefix], s=100, c='r', marker='*',alpha=0.8)\n",
    "        ax3.set_xlabel('K', fontdict={'size': 16})\n",
    "        ax3.set_ylabel('Davies Bouldin Score', fontdict={'size': 16})\n",
    "        ax3.set_title(\"DBI\", fontdict={'size': 18})\n",
    "        ax3.legend(loc='best')\n",
    "\n",
    "        ##plt.suptitle((\"Learning curve for K values of ScC-WGCNA and KMeans clustering on %s data\" % prefix), fontsize=14, fontweight='bold')\n",
    "        plt.suptitle((\"Learning curve for K values of ScC-WGCNA clustering on %s data\" % prefix), fontsize=20, fontweight='bold')\n",
    "        fig = plt.gcf()\n",
    "        ##fig.savefig(outdir+prefix+\"/\"+prefix+\".Learning curve for K values of ScC-WGCNA and KMeans clustering on %s data.png\" % prefix, dpi=1080)#\n",
    "        fig.savefig(outdir+prefix+\"/\"+prefix+\".Learning curve for K values of ScC-WGCNA clustering on %s data.pdf\" % prefix, dpi=100)#\n",
    "        fig.savefig(outdir+prefix+\"/\"+prefix+\".Learning curve for K values of ScC-WGCNA clustering on %s data.png\" % prefix, dpi=1080)#\n",
    "        plt.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"\\n==============================\")\n",
    "        print(\"Error processing %s\" % prefix)\n",
    "        print(e)\n",
    "        print(\"==============================\\n\")\n",
    "        continue\n",
    "    print(\"============================\\n\")\n",
    "    \n",
    "\n",
    "print(powers)\n",
    "print(default_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2f470-33d4-4b2f-ab2a-b1411c4c4beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for prefix_index, prefix in enumerate(cancer_names):\n",
    "#     prefix = prefix\n",
    "#     print(\"%s==========>\\n\" % prefix)\n",
    "\n",
    "#     ### The visualization of the  evaluation score  ###\n",
    "#     fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "#     fig.set_size_inches(18, 6)\n",
    "\n",
    "#     #xticks = range(len(score_pckmeans[\"SI\"][prefix_index]))# K_sequence #\n",
    "    \n",
    "#     #ax1.plot(xticks[prefix], score_wgcna[\"SI\"], color = 'red', linewidth = 1.0, linestyle = '-', label='WGCNA', marker='d', markerfacecolor='red', markersize=10)\n",
    "#     ax1.plot(xticks[prefix], score_pckmeans[\"SI\"][prefix], color = 'green', linewidth = 1.0, linestyle = '--', label='ScC-WGCNA', marker='^', markerfacecolor='green', markersize=10)\n",
    "#     #ax1.plot(xticks[prefix], score_kmeans[\"SI\"][prefix], color = 'blue', linewidth = 1.0, linestyle = '-.', label='KMeans', marker='o', markerfacecolor='blue', markersize=10)\n",
    "#     ax1.scatter(WGCNA_k[prefix], score_wgcna[\"SI\"][prefix], s=100, c='r', marker='*',alpha=0.8)\n",
    "#     ax1.set_xlabel('K', fontdict={'size': 16})\n",
    "#     ax1.set_ylabel('Silhouette Coefficient Score', fontdict={'size': 16})\n",
    "#     ax1.set_title(\"SI\", fontdict={'size': 18})\n",
    "#     ax1.legend(loc='best')\n",
    "#     #plt.yticks(range(0, 50, 5)) \n",
    "#     #plt.grid(True, linestyle='--', alpha=0.5)#添加网格\n",
    "#     #在对应坐标处更换名称\n",
    "#     #ax1.yticks([-2,-1,0,1,2],['really bad','b','c','d','good'])\n",
    "    \n",
    "#     #ax2.plot(x, score_wgcna[\"CH\"], color = 'red', linewidth = 1.0, linestyle = '-', label='WGCNA', marker='d', markerfacecolor='red', markersize=10)\n",
    "#     ax2.plot(xticks[prefix], score_pckmeans[\"CH\"][prefix], color = 'green', linewidth = 1.0, linestyle = '--', label='ScC-WGCNA', marker='^', markerfacecolor='green', markersize=10)\n",
    "#     #ax2.plot(xticks[prefix], score_kmeans[\"CH\"][prefix], color = 'blue', linewidth = 1.0, linestyle = '-.', label='KMeans', marker='o', markerfacecolor='blue', markersize=10)\n",
    "#     ax2.scatter(WGCNA_k[prefix], score_wgcna[\"CH\"][prefix], s=100, c='r', marker='*',alpha=0.8)\n",
    "#     ax2.set_xlabel('K', fontdict={'size': 16})\n",
    "#     ax2.set_ylabel('Calinski Harabasz Score', fontdict={'size': 16})\n",
    "#     ax2.set_title(\"CH\", fontdict={'size': 18})\n",
    "#     ax2.legend(loc='best')\n",
    "    \n",
    "#     #ax3.plot(x, score_wgcna[\"DBI\"], color = 'red', linewidth = 1.0, linestyle = '-', label='WGCNA', marker='d', markerfacecolor='red', markersize=10)\n",
    "#     ax3.plot(xticks[prefix], score_pckmeans[\"DBI\"][prefix], color = 'green', linewidth = 1.0, linestyle = '--', label='ScC-WGCNA', marker='^', markerfacecolor='green', markersize=10)\n",
    "#     #ax3.plot(xticks[prefix], score_kmeans[\"DBI\"][prefix], color = 'blue', linewidth = 1.0, linestyle = '-.', label='KMeans', marker='o', markerfacecolor='blue', markersize=10)\n",
    "#     ax3.scatter(WGCNA_k[prefix], score_wgcna[\"DBI\"][prefix], s=100, c='r', marker='*',alpha=0.8)\n",
    "#     ax3.set_xlabel('K', fontdict={'size': 16})\n",
    "#     ax3.set_ylabel('Davies Bouldin Score', fontdict={'size': 16})\n",
    "#     ax3.set_title(\"DBI\", fontdict={'size': 18})\n",
    "#     ax3.legend(loc='best')\n",
    "    \n",
    "#     ##plt.suptitle((\"Learning curve for K values of ScC-WGCNA and KMeans clustering on %s data\" % prefix), fontsize=14, fontweight='bold')\n",
    "#     plt.suptitle((\"Learning curve for K values of ScC-WGCNA clustering on %s data\" % prefix), fontsize=20, fontweight='bold')\n",
    "#     fig = plt.gcf()\n",
    "#     ##fig.savefig(outdir+prefix+\"/\"+prefix+\".Learning curve for K values of ScC-WGCNA and KMeans clustering on %s data.png\" % prefix, dpi=1080)#\n",
    "#     fig.savefig(outdir+prefix+\"/\"+prefix+\".Learning curve for K values of ScC-WGCNA clustering on %s data.png\" % prefix, dpi=1080)#\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9972ea48-f2ef-4558-b67c-5b377d408f3d",
   "metadata": {},
   "source": [
    "### 在n个数据集上对m种聚类算法用三种外部聚类评估指标进行对比评估 以学习曲线选取最佳K值设置K 可以设置共表达网络构建所用的距离度量方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b469e84-3798-407f-a072-1d5013f6d30d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### 在n个数据集上对m种聚类算法用三种外部聚类评估指标进行对比评估 以学习曲线选取最佳K值设置K 可以设置共表达网络构建所用的距离度量方法 ###\n",
    "### 没有异常处理 ###\n",
    "\n",
    "score_wgcna = dict(SI = [], CH = [], DBI = [])\n",
    "score_pckmeans = dict(SI = [], CH = [], DBI = [])\n",
    "#score_kmeans = dict(SI = [], CH = [], DBI = [])\n",
    "\n",
    "if distance==\"dcorr\":\n",
    "    K = {\"BLCA\": 5, \"BRCA\": 5, \"COAD\": 5, \"KIRC\": 5, \"LUAD\": 5, \"LUSC\": 5, \"STAD\": 5,  \"PAAD\": 5} \n",
    "elif distance==\"pearson\":\n",
    "    K = {\"BLCA\": 5, \"BRCA\": 5, \"COAD\": 5, \"KIRC\": 5, \"LUAD\": 5, \"LUSC\": 5, \"STAD\": 5,  \"PAAD\": 5}\n",
    "else:\n",
    "    K = WGCNA_k\n",
    "\n",
    "max_density = []\n",
    "for prefix in cancer_names:\n",
    "    #prefix = \"KIRC\"\n",
    "    prefix = prefix\n",
    "    print(\"###==================== %s ====================###\\n\" % prefix)\n",
    "    \n",
    "    if not os.path.exists(outdir+prefix):\n",
    "        os.makedirs(outdir+prefix)\n",
    "        \n",
    "\n",
    "    data = pd.read_csv(data_indir+prefix+\"/\"+prefix+\".tumor.tpm.updown.feature_selection.csv\", sep=',', index_col=0)\n",
    "    print(\"Input: data.shape\", data.shape)\n",
    "    print(\"NAN check for data: \", data.isnull().values.sum())\n",
    "    '''\n",
    "    if distance==\"Pearson\":\n",
    "        similarity = data.T.corr()#dcor## # 计算相关系数，得到一个矩阵\n",
    "    elif distance==\"snn\":   \n",
    "        snn_sim = snn_sim_matrix(data, k=5)\n",
    "    elif distance==\"dcorr\":\n",
    "        similarity = pd.read_csv(dcorr_dir+prefix+\"/\"+prefix+\".tumor.tpm.updown.feature_selection.dcorr.csv\", index=False, sep=',')\n",
    "    else:\n",
    "        print(\"input parameter error：Undefined distance type.\")\n",
    "\n",
    "    sim = pd.DataFrame(similarity, index=data.index, columns=data.index)\n",
    "    print(\"NAN check: \", sim.isnull().values.sum())\n",
    "    #先删除全是空值的行和列\n",
    "    if sim.isnull().values.ravel().sum():\n",
    "        sim.drop(sim.columns[sim.isnull().all(axis=1)].tolist(), inplace=True)#删除全是NAN的行\n",
    "        sim = sim[sim.columns[~sim.isnull().all(axis=0)].tolist()]#删除全是NAN的列\n",
    "        #再用0填充NAN\n",
    "        sim.fillna(0, inplace=True)#用0填补缺失值\n",
    "    print(\"After processing NA: sim.shape\", sim.shape)\n",
    "    sim.to_csv(outdir+prefix+\"/\"+prefix+\".\"+distance+\"_sim.csv\", index=False, sep=',')\n",
    "\n",
    "    #Check scale free topology\n",
    "    # Create an adjacency network； ^6 近似无标度化\n",
    "    # here we define the adjacency matrix using soft thresholding with beta=6\n",
    "    ADJ = abs(sim)**powers[prefix] # 近似无标度化\n",
    "    print(\"Input: ADJ\", \"Max: {}\".format(ADJ.values.ravel().max()), \"Min: {}\".format(ADJ.values.ravel().min()), sep=\"\\n\")\n",
    "    print(\"NAN check: \", ADJ.isnull().values.sum())\n",
    "    #ADJ.to_csv(\"./outdir/\"+Inputfile+\".\"+distance+\".ADJ.csv\", index=False, sep=',')\n",
    "\n",
    "    values = -np.sort(-(ADJ.sum().values))# 包含每个柱子对应值的序列\n",
    "    index = sim.index# 包含每个柱子下标的序列    \n",
    "    draw_bar(values)\n",
    "\n",
    "    # Compute topological overlap\n",
    "    #from topological_overlap_measure import TOMsimilarity\n",
    "    from topological_overlap_measure import *\n",
    "    #from soothsayer.networks import topological_overlap_measure\n",
    "    TOM = TOMsimilarity(ADJ)#把邻接矩阵转换为拓扑重叠矩阵topological_overlap_measure\n",
    "    dissTOM = 1 - TOM\n",
    "\n",
    "    TOM.to_csv(outdir+prefix+\"/\"+prefix+\".\"+distance+\".TOM.csv\", index=False, sep=',')\n",
    "    dissTOM.to_csv(outdir+prefix+\"/\"+prefix+\".\"+distance+\".dissTOM.csv\", index=False, sep=',')\n",
    "    '''\n",
    "    \n",
    "    ADJ = pd.read_csv(outdir+prefix+\"/\"+prefix+\".\"+distance+\".ADJ.csv\", sep=',')\n",
    "    ADJ.index = ADJ.columns\n",
    "    #计算邻接性\n",
    "    Connectivity = ADJ.values\n",
    "    row, col = np.diag_indices_from(Connectivity)\n",
    "    Connectivity[row, col] = 0\n",
    "    Connectivity = pd.DataFrame(Connectivity, columns=ADJ.columns)\n",
    "    Connectivity.to_csv(outdir+prefix+\"/\"+prefix+\".\"+distance+\".Connectivity.csv\", index=False, sep=',')\n",
    "    \n",
    "    TOM = pd.read_csv(outdir+prefix+\"/\"+prefix+\".\"+distance+\"_TOM.csv\", sep=',')\n",
    "    TOM.index = TOM.columns \n",
    "    \n",
    "    dissTOM = pd.read_csv(outdir+prefix+\"/\"+prefix+\".\"+distance+\".dissTOM.csv\", sep=',')\n",
    "    dissTOM.index = dissTOM.columns\n",
    "    \n",
    "    X = dissTOM\n",
    "    \n",
    "    try:\n",
    "        # 使用TSNE进行降维处理。\n",
    "        tsne = TSNE(n_components=2, learning_rate=100, random_state=0).fit_transform(TOM)\n",
    "    except Exception as e:\n",
    "        print(\"\\n==============================\")\n",
    "        print(\"Error occurs in %s process of %s\" % (tsne, prefix))\n",
    "        print(e)        \n",
    "        print(\"==============================\\n\")\n",
    "        tsne = TSNE(n_components=2, learning_rate=100, random_state=0).fit_transform(ADJ)\n",
    "    \n",
    "    # 读入约束基因集，构建成对约束\n",
    "    df = open(mldir+prefix+\"/\"+prefix+\".ml.txt\",'r')\n",
    "    geneslist = df.readline().split(\"\\t\")\n",
    "    geneslist.pop()#去掉最后的换行符\n",
    "    ml = set()\n",
    "    byt = df.readlines()\n",
    "    for index,value in enumerate(byt):\n",
    "        temp = value.split(\"\\t\")\n",
    "        temp.pop()#默认删除最后一个元素，并返回值\n",
    "        #temp.remove(\"\\n\")#删除元素temp\n",
    "        byt[index] = temp\n",
    "        for i in range(len(temp)):\n",
    "            for j in range(i+1, len(temp)):\n",
    "                ml.add((geneslist.index(temp[i]),geneslist.index(temp[j])))\n",
    "    print(\"Constraints in pairs gene number:%d\\n\" % len(ml))\n",
    "\n",
    "    ### 可视化WGCNA聚类结果作为参考 ###\n",
    "    print(\"WGCNA==========>\")\n",
    "    wgcna_y_pred = pd.read_csv(labelsdir+prefix+\"/\"+prefix+\".wgcna.result.csv\", index_col=False)\n",
    "    wgcna_y_pred.index = wgcna_y_pred[\"gene\"].values\n",
    "    wgcna_y_pred = wgcna_y_pred.loc[X.index]\n",
    "    wgcna_labels = wgcna_y_pred[\"dynamicMods\"].values\n",
    "    print(\"value_counts:\\n\", pd.DataFrame(pd.value_counts(wgcna_labels)).T)\n",
    "    labels_counts = pd.DataFrame(pd.value_counts(wgcna_labels))\n",
    "    labels_counts.insert(0, \"clusters\", labels_counts.index)\n",
    "    labels_counts.columns = [\"clusters\", \"counts\"]\n",
    "    labels_counts.to_csv(outdir+prefix+\"/\"+prefix+\".WGCNA_clustering\"+\".labels_counts.csv\", index=False)\n",
    "    pd.DataFrame(np.array([X.index, wgcna_labels]).T, columns=[\"gene\", \"labels\"]).to_csv(outdir+prefix+\"/\"+prefix+\".WGCNA_clustering\"+\".cluster_labels.csv\", index=False)#, header=None\n",
    "\n",
    "    unique_labels = np.unique(wgcna_labels)\n",
    "    ##分类个数：lables中包含-1，表示噪声点\n",
    "    n_clusters_ =len(np.unique(wgcna_labels)) - (1 if -1 in wgcna_labels else 0) \n",
    "    print(\"Number of clusters with WGCNA:%d\" % n_clusters_)\n",
    "    wgcna_k = n_clusters_\n",
    "\n",
    "    SI = silhouette_score(X, wgcna_labels)\n",
    "    CH = calinski_harabasz_score(X, wgcna_labels)\n",
    "    DBI = davies_bouldin_score(X, wgcna_labels)\n",
    "    score_wgcna[\"SI\"].append(SI)\n",
    "    score_wgcna[\"CH\"].append(CH)\n",
    "    score_wgcna[\"DBI\"].append(DBI)\n",
    "    print(\"For n_clusters =\", n_clusters_,\n",
    "            \"\\nThe average silhouette_score is :\", SI)\n",
    "    print(\"Calinski-Harabasz Score\",  CH,\n",
    "             \"\\nDavies Bouldin score is :\", DBI)\n",
    "\n",
    "    sample_silhouette_values = silhouette_samples(X, wgcna_labels)\n",
    "\n",
    "    plt.clf() # 使用 plt.clf() 清理掉 axes\n",
    "    # fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "    plt.rcParams.update({'font.family': 'Times New Roman'})\n",
    "    plt.rcParams.update({'font.weight': 'normal'})\n",
    "    plt.rcParams.update({'font.size': 20})\n",
    "    \n",
    "    ax1=fig.add_subplot(121)\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    ax1.set_ylim([0, X.shape[0] + (n_clusters_ + 1) * 10])\n",
    "\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters_):\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[wgcna_labels == i]\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "        color = cm.nipy_spectral(float(i)/n_clusters_)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper)\n",
    "                         ,ith_cluster_silhouette_values\n",
    "                         ,facecolor=color\n",
    "                         ,alpha=0.7\n",
    "                         )\n",
    "        ax1.text(-0.05\n",
    "                 , y_lower + 0.5 * size_cluster_i\n",
    "                 , str(i))\n",
    "        y_lower = y_upper + 10\n",
    "    ax1.set_title(\"The Silhouette plot for the various clusters.\", fontsize=18)\n",
    "    ax1.set_xlabel(\"The Silhouette coefficient values\", fontsize=16)\n",
    "    ax1.set_ylabel(\"Cluster label\", fontsize=16)\n",
    "    ax1.axvline(x=SI, color=\"red\", linestyle=\"--\")\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    #colors = cm.nipy_spectral(wgcna_labels.astype(float) / n_clusters_)\n",
    "    colors = Labels2Color(X, wgcna_labels)['colorcode']\n",
    "    ax2 = fig.add_subplot(1, 2, 2, projection='3d') \n",
    "    ax2.scatter3D(tsne[:, 0], tsne[:, 1],tsne[:, 2]\n",
    "               ,marker='o'\n",
    "               ,s=4\n",
    "               ,c=colors\n",
    "               )\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\", fontsize=18)\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\", fontsize=16)\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\", fontsize=16)\n",
    "    ax2.set_zlabel(\"z\", fontsize=20)\n",
    "    plt.suptitle((\"Silhouette analysis for WGCNA clustering on %s data with n_clusters = %d\" % (prefix, wgcna_k)),\n",
    "                 fontsize=20, fontweight='bold')\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(outdir+prefix+\"/\"+prefix+\".Silhouette analysis for WGCNA clustering on %s data.png\" % prefix, bbox_inches='tight', dpi=1080)\n",
    "    fig.savefig(outdir+prefix+\"/\"+prefix+\".Silhouette analysis for WGCNA clustering on %s data.pdf\" % prefix, bbox_inches='tight', dpi=100)\n",
    "    #plt.show()\n",
    "\n",
    "    ### 测试聚类效果 ###\n",
    "    print(\"\\nPCKMeans==========>\")\n",
    "\n",
    "    t1 = time.time()\n",
    "    pckm = PCKMeans(n_clusters=K[prefix])#, distance_type='euclidean'\n",
    "    pckm.fit(np.array(X), ml=ml)#\n",
    "    t2 = time.time()\n",
    "    print (\"the time of clustering is %.5fs\" % (t2 - t1))\n",
    "    pckm_labels = pckm.labels_ \n",
    "\n",
    "    \n",
    "    print(\"value_counts:\\n\", pd.DataFrame(pd.value_counts(pckm_labels)).T)\n",
    "    labels_counts = pd.DataFrame(pd.value_counts(pckm_labels))\n",
    "    labels_counts.insert(0, \"clusters\", labels_counts.index)\n",
    "    labels_counts.columns = [\"clusters\", \"counts\"]\n",
    "    labels_counts.to_csv(outdir+prefix+\"/\"+prefix+\".\"+distance+\".PCKMeans_clustering\"+\".labels_counts.csv\", index=False)\n",
    "    pd.DataFrame(np.array([X.index, pckm_labels]).T, columns=[\"gene\", \"labels\"]).to_csv(outdir+prefix+\"/\"+prefix+\".\"+distance+\".PCKMeans_clustering\"+\".cluster_labels.csv\", index=False)#, header=None\n",
    "    unique_labels = np.unique(pckm_labels)\n",
    "    n_clusters_ =len(np.unique(pckm_labels)) - (1 if -1 in pckm_labels else 0)\n",
    " \n",
    "    #每个模块的基因数条形图\n",
    "    width = 0.35# 柱子的宽度\n",
    "    plt.clf() # 使用 plt.clf() 清理掉 axes\n",
    "    fig = plt.figure(figsize=(6, 6), dpi=200)# 创建画布, 并设置分辨率为 80像素/每英寸\n",
    "    plt.subplot(111)# 创建一个子图\n",
    "    plt.title(\"Number of genes in the module\", fontsize=18)\n",
    "    plt.xlabel(\"Module\", fontsize=16)\n",
    "    plt.ylabel(\"Number of genes\", fontsize=16)\n",
    "    plt.bar(labels_counts.loc[:, \"clusters\"], labels_counts.loc[:, \"counts\"], width = width, color=\"#87CEFA\") # 绘制柱状图, 每根柱子的颜色为紫罗兰色\n",
    "    fig.savefig(outdir+prefix+\"/\"+prefix+\".\"+distance+\".Number of genes in the module.png\", bbox_inches='tight', dpi=1080)  # 保存图片，如果不设置 bbox_inches='tight'，保存的图片有可能显示不全\n",
    "    fig.savefig(outdir+prefix+\"/\"+prefix+\".\"+distance+\".Number of genes in the module.pdf\", bbox_inches='tight', dpi=200)  # 保存图片，如果不设置 bbox_inches='tight'，保存的图片有可能显示不全\n",
    "    pd.DataFrame.from_dict({\"clusters\":labels_counts.loc[:, \"clusters\"], \"counts\":labels_counts.loc[:, \"counts\"]}).to_csv(outdir+prefix+\"/\"+prefix+\".\"+distance+\".Number of genes in the module.csv\", index=False, sep=',')\n",
    "    \n",
    "    \n",
    "    #模块内平均连通性\n",
    "    values = []\n",
    "    for k in np.sort(np.unique(pckm_labels)):      \n",
    "        values.append(sum(Connectivity.loc[pckm_labels==k, pckm_labels==k].sum())/sum(pckm_labels==k))\n",
    "    width = 0.35# 柱子的宽度\n",
    "    #fig = plt.figure(figsize=(6, 6), dpi=200)# 创建画布, 并设置分辨率为 80像素/每英寸\n",
    "    plt.clf() # 使用 plt.clf() 清理掉 axes\n",
    "    plt.subplot(111)# 创建一个子图\n",
    "    plt.title(\"Mean Connectivity of module\", fontsize=18)\n",
    "    plt.xlabel(\"Module\", fontsize=16)\n",
    "    plt.ylabel(\"Mean Connectivity\", fontsize=16)\n",
    "    plt.bar(np.sort(np.unique(pckm_labels)), values, width = width, color=\"#87CEFA\") # 绘制柱状图, 每根柱子的颜色为紫罗兰色ind-width/2\n",
    "    fig.savefig(outdir+prefix+\"/\"+prefix+\".\"+distance+\".Mean_Connectivity_of_module.png\", dpi=1080, bbox_inches='tight')\n",
    "    fig.savefig(outdir+prefix+\"/\"+prefix+\".\"+distance+\".Mean_Connectivity_of_module.pdf\", dpi=200, bbox_inches='tight')\n",
    "    pd.DataFrame.from_dict({'pckm_labels':np.sort(np.unique(pckm_labels)), 'values':values}).to_csv(outdir+prefix+\"/\"+prefix+\".\"+distance+\".Mean_Connectivity_of_module.csv\", index=False, sep=',')\n",
    "    \n",
    "    \n",
    "    #模块密度\n",
    "    values = []\n",
    "    for k in np.sort(np.unique(pckm_labels)):      \n",
    "        values.append(sum(Connectivity.loc[pckm_labels==k, pckm_labels==k].sum())/(sum(pckm_labels==k)*(sum(pckm_labels==k)-1)))\n",
    "    max_density.append(max(values))\n",
    "    width = 0.35# 柱子的宽度\n",
    "    #fig = plt.figure(figsize=(6, 6), dpi=200)# 创建画布, 并设置分辨率为 80像素/每英寸\n",
    "    plt.clf() # 使用 plt.clf() 清理掉 axes\n",
    "    plt.subplot(111)# 创建一个子图\n",
    "    plt.title(\"Density of module\", fontsize=18)\n",
    "    plt.xlabel(\"Module\", fontsize=16)\n",
    "    plt.ylabel(\"Density\", fontsize=16)\n",
    "    plt.bar(np.sort(np.unique(pckm_labels)), values, width = width, color=\"#87CEFA\") # 绘制柱状图, 每根柱子的颜色为紫罗兰色ind-width/2\n",
    "    fig.savefig(outdir+prefix+\"/\"+prefix+\".\"+distance+\".density_of_module.png\", dpi=1080, bbox_inches='tight')\n",
    "    fig.savefig(outdir+prefix+\"/\"+prefix+\".\"+distance+\".density_of_module.pdf\", dpi=200, bbox_inches='tight')\n",
    "    pd.DataFrame.from_dict({'pckm_labels':np.sort(np.unique(pckm_labels)), 'values':values}).to_csv(outdir+prefix+\"/\"+prefix+\".\"+distance+\".density_of_module.csv\", index=False, sep=',')\n",
    "    \n",
    "    \n",
    "    # 参数评估\n",
    "    SI = silhouette_score(X, pckm_labels)\n",
    "    CH = calinski_harabasz_score(X, pckm_labels)\n",
    "    DBI = davies_bouldin_score(X, pckm_labels)\n",
    "    score_pckmeans[\"SI\"].append(SI)\n",
    "    score_pckmeans[\"CH\"].append(CH)\n",
    "    score_pckmeans[\"DBI\"].append(DBI)\n",
    "    print(\"For n_clusters =\", n_clusters_,\n",
    "            \"\\nThe average silhouette_score is :\", SI)\n",
    "    print(\"Calinski-Harabasz Score\",  CH,\n",
    "             \"\\nDavies Bouldin score is :\", DBI)\n",
    "\n",
    "    sample_silhouette_values = silhouette_samples(X, pckm_labels)\n",
    "\n",
    "\n",
    "    plt.clf() # 使用 plt.clf() 清理掉 axes\n",
    "    fig=plt.figure()   \n",
    "    #fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7) \n",
    "    plt.rcParams.update({'font.family': 'Times New Roman'})\n",
    "    plt.rcParams.update({'font.weight': 'normal'})\n",
    "    plt.rcParams.update({'font.size': 20})\n",
    "    \n",
    "    ax1=fig.add_subplot(121)\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    ax1.set_ylim([0, X.shape[0] + (n_clusters_ + 1) * 10])\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters_):\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[pckm_labels == i]\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "        color = cm.nipy_spectral(float(i)/n_clusters_)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper)\n",
    "                         ,ith_cluster_silhouette_values\n",
    "                         ,facecolor=color\n",
    "                         ,alpha=0.7\n",
    "                         )\n",
    "        ax1.text(-0.05\n",
    "                 , y_lower + 0.5 * size_cluster_i\n",
    "                 , str(i))\n",
    "        y_lower = y_upper + 10\n",
    "    ax1.set_title(\"The Silhouette plot for the various clusters.\", fontsize=18)\n",
    "    ax1.set_xlabel(\"The Silhouette coefficient values\", fontsize=16)\n",
    "    ax1.set_ylabel(\"Cluster label\", fontsize=16)\n",
    "    ax1.axvline(x=SI, color=\"red\", linestyle=\"--\")\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    #colors = cm.nipy_spectral(pckm_labels.astype(float) / n_clusters_)\n",
    "    colors = Labels2Color(X, pckm_labels)['colorcode']\n",
    "    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    ax2.scatter3D(tsne[:, 0], tsne[:, 1],tsne[:, 2]\n",
    "               ,marker='o'\n",
    "               ,s=4\n",
    "               ,c=colors\n",
    "               )\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\", fontsize=18)\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\", fontsize=16)\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\", fontsize=16, rotation=38) #, rotation=38 y 轴名称旋转 38 度\n",
    "    ax2.set_zlabel('Z')\n",
    "    plt.suptitle((\"Silhouette analysis for ScC-WGCNA clustering on %s data with n_clusters = %d\" % (prefix, n_clusters_)),\n",
    "                 fontsize=20, fontweight='bold')\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(outdir+prefix+\"/\"+prefix+\".\"+distance+\".Silhouette analysis for ScC-WGCNA clustering on %s data.png\" % prefix, bbox_inches='tight', dpi=1080)  # 保存图片，如果不设置 bbox_inches='tight'，保存的图片有可能显示不全\n",
    "    fig.savefig(outdir+prefix+\"/\"+prefix+\".\"+distance+\".Silhouette analysis for ScC-WGCNA clustering on %s data.pdf\" % prefix, bbox_inches='tight', dpi=200)  # 保存图片，如果不设置 bbox_inches='tight'，保存的图片有可能显示不全\n",
    "    #plt.show()\n",
    "\n",
    "    '''\n",
    "    ### 测试KMeans聚类效果 ###\n",
    "    #from sklearn.cluster import KMeans\n",
    "\n",
    "    print(\"\\nKMeans==========>\")\n",
    "    t1 = time.time()\n",
    "    km = KMeans(n_clusters=K[prefix])\n",
    "    km.fit(X)\n",
    "    t2 = time.time()\n",
    "    print (\"the time of clustering is %.5fs\" % (t2 - t1))\n",
    "    km_labels = km.labels_\n",
    "    print(\"value_counts:\\n\", pd.DataFrame(pd.value_counts(km_labels)).T)\n",
    "    labels_counts = pd.DataFrame(pd.value_counts(km_labels))\n",
    "    labels_counts.insert(0, \"clusters\", labels_counts.index)\n",
    "    labels_counts.columns = [\"clusters\", \"counts\"]\n",
    "    labels_counts.to_csv(outdir+prefix+\"/\"+prefix+\".KMeans_clustering\"+\".labels_counts.csv\", index=False)\n",
    "    pd.DataFrame(np.array([X.index, km_labels]).T, columns=[\"gene\", \"labels\"]).to_csv(outdir+prefix+\"/\"+prefix+\".KMeans_clustering\"+\".cluster_labels.csv\", index=False)#, header=None\n",
    "    unique_labels = np.unique(km_labels)\n",
    "    n_clusters_ =len(np.unique(km_labels)) - (1 if -1 in km_labels else 0)\n",
    "\n",
    "    SI = silhouette_score(X, km_labels)\n",
    "    CH = calinski_harabasz_score(X, km_labels)\n",
    "    DBI = davies_bouldin_score(X, km_labels)\n",
    "    score_kmeans[\"SI\"].append(SI)\n",
    "    score_kmeans[\"CH\"].append(CH)\n",
    "    score_kmeans[\"DBI\"].append(DBI)\n",
    "    print(\"For n_clusters =\", n_clusters_,\n",
    "            \"\\nThe average silhouette_score is :\", SI)\n",
    "    print(\"Calinski-Harabasz Score\",  CH,\n",
    "             \"\\nDavies Bouldin score is :\", DBI)\n",
    "\n",
    "\n",
    "    sample_silhouette_values = silhouette_samples(X, km_labels)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    ax1.set_ylim([0, X.shape[0] + (n_clusters_ + 1) * 10])\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters_):\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[km_labels == i]\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "        color = cm.nipy_spectral(float(i)/n_clusters_)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper)\n",
    "                         ,ith_cluster_silhouette_values\n",
    "                         ,facecolor=color\n",
    "                         ,alpha=0.7\n",
    "                         )\n",
    "        ax1.text(-0.05\n",
    "                 , y_lower + 0.5 * size_cluster_i\n",
    "                 , str(i))\n",
    "        y_lower = y_upper + 10\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "    ax1.axvline(x=SI, color=\"red\", linestyle=\"--\")\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    #colors = cm.nipy_spectral(pckm_labels.astype(float) / n_clusters_)\n",
    "    colors = Labels2Color(X, km_labels)['colorcode']\n",
    "    ax2.scatter(tsne[:, 0], tsne[:, 1]\n",
    "               ,marker='o'\n",
    "               ,s=6\n",
    "               ,c=colors\n",
    "               )\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on %s data with n_clusters = %d\" % (prefix, n_clusters_)),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(outdir+prefix+\"/\"+prefix+\".\"+distance+\".Silhouette analysis for KMeans clustering on %s data.png\" % prefix, dpi=1080)#\n",
    "    #plt.show()\n",
    "    '''\n",
    "\n",
    "    ### The visualization of the clustered data ###\n",
    "    plt.clf() # 使用 plt.clf() 清理掉 axes\n",
    "    # set up a figure twice as wide as it is tall\n",
    "    #fig = plt.figure(figsize=plt.figaspect(0.5))\n",
    "    #fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "    #fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 6)\n",
    "\n",
    "    colors1 = Labels2Color(X, wgcna_labels)['colorcode']\n",
    "    # set up the axes for the first plot\n",
    "    ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "    ax1.scatter3D(tsne[:, 0], tsne[:, 1], tsne[:, 2]\n",
    "               ,marker='o'\n",
    "               ,s=4\n",
    "               ,c=colors1\n",
    "               )\n",
    "    ax1.set_title(\"WGCNA with n_clusters = %d\" % wgcna_k, fontsize=18)\n",
    "    ax1.set_xlabel(\"Feature space for the 1st feature\", fontsize=16)\n",
    "    ax1.set_ylabel(\"Feature space for the 2nd feature\", fontsize=16)\n",
    "    ax1.set_zlabel(\"z\", fontsize=16)\n",
    "    \n",
    "    colors2 = Labels2Color(X, pckm_labels)['colorcode']\n",
    "    # set up the axes for the first plot\n",
    "    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    ax2.scatter3D(tsne[:, 0], tsne[:, 1], tsne[:, 2]\n",
    "               ,marker='o'\n",
    "               ,s=4\n",
    "               ,c=colors2\n",
    "               )\n",
    "    ax2.set_title(\"PCKMeans with n_clusters = %d\" % K[prefix], fontsize=18)\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\", fontsize=16)\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\", fontsize=16)\n",
    "    ax2.set_zlabel(\"z\", fontsize=16)\n",
    "\n",
    "    '''\n",
    "    colors3 = Labels2Color(X, km_labels)['colorcode']\n",
    "    ax3.scatter(tsne[:, 0], tsne[:, 1]\n",
    "               ,marker='o'\n",
    "               ,s=6\n",
    "               ,c=colors3\n",
    "               )\n",
    "    ax3.set_title(\"KMeans with n_clusters = %d\" % K[prefix])\n",
    "    ax3.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    ax3.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "    '''\n",
    "    plt.suptitle((\"The visualization of %s data clustering results\" % prefix),\n",
    "                 fontsize=20, fontweight='bold')\n",
    "    fig = plt.gcf()\n",
    "    #fig.savefig(outdir+prefix+\"/\"+prefix+\".the visualization of %s data with WGCNA, ScC-WGCNA and KMeans clustering results.png\" % prefix, dpi=1080)#\n",
    "    fig.savefig(outdir+prefix+\"/\"+prefix+\".\"+distance+\".the visualization of %s data with WGCNA and ScC-WGCNA clustering results.png\" % prefix, bbox_inches='tight', dpi=1080)\n",
    "    fig.savefig(outdir+prefix+\"/\"+prefix+\".\"+distance+\".the visualization of %s data with WGCNA and ScC-WGCNA clustering results.pdf\" % prefix, bbox_inches='tight', dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"================================================\\n\")\n",
    "\n",
    "### The visualization of the  evaluation score  ###\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "fig.set_size_inches(24, 8)\n",
    "\n",
    "x = cancer_names #range(len(score_wgcna[\"SI\"]))# \n",
    "ax1.plot(x, score_wgcna[\"SI\"], color = 'red', linewidth = 1.0, linestyle = '-', label='WGCNA', marker='d', markerfacecolor='red', markersize=10)\n",
    "ax1.plot(x, score_pckmeans[\"SI\"], color = 'green', linewidth = 1.0, linestyle = '--', label='PCKMeans', marker='^', markerfacecolor='green', markersize=10)\n",
    "#ax1.plot(x, score_kmeans[\"SI\"], color = 'blue', linewidth = 1.0, linestyle = '-.', label='KMeans', marker='o', markerfacecolor='blue', markersize=10)\n",
    "ax1.set_xlabel('datasets', fontdict={'size': 16})\n",
    "ax1.set_ylabel('Silhouette Coefficient Score', fontdict={'size': 16})\n",
    "ax1.set_title(\"SI\", fontdict={'size': 18})\n",
    "ax1.legend(loc='best')\n",
    "\n",
    "ax2.plot(x, score_wgcna[\"CH\"], color = 'red', linewidth = 1.0, linestyle = '-', label='WGCNA', marker='d', markerfacecolor='red', markersize=10)\n",
    "ax2.plot(x, score_pckmeans[\"CH\"], color = 'green', linewidth = 1.0, linestyle = '--', label='PCKMeans', marker='^', markerfacecolor='green', markersize=10)\n",
    "#ax2.plot(x, score_kmeans[\"CH\"], color = 'blue', linewidth = 1.0, linestyle = '--', label='KMeans', marker='o', markerfacecolor='blue', markersize=10)\n",
    "ax2.set_xlabel('datasets', fontdict={'size': 16})\n",
    "ax2.set_ylabel('Calinski Harabasz Score', fontdict={'size': 16})\n",
    "ax2.set_title(\"CH\", fontdict={'size': 18})\n",
    "ax2.legend(loc='best')\n",
    "\n",
    "ax3.plot(x, score_wgcna[\"DBI\"], color = 'red', linewidth = 1.0, linestyle = '-', label='WGCNA', marker='d', markerfacecolor='red', markersize=10)\n",
    "ax3.plot(x, score_pckmeans[\"DBI\"], color = 'green', linewidth = 1.0, linestyle = '--', label='PCKMeans', marker='^', markerfacecolor='green', markersize=10)\n",
    "#ax3.plot(x, score_kmeans[\"DBI\"], color = 'blue', linewidth = 1.0, linestyle = '--', label='KMeans', marker='o', markerfacecolor='blue', markersize=10)\n",
    "ax3.set_xlabel('datasets', fontdict={'size': 16})\n",
    "ax3.set_ylabel('Davies Bouldin Score', fontdict={'size': 16})\n",
    "ax3.set_title(\"DBI\", fontdict={'size': 18})\n",
    "ax3.legend(loc='best')\n",
    "\n",
    "#plt.suptitle((\"SI,CH and DBI scores for WGCNA, ScC-WGCNA and KMeans clustering on sample data\"), fontsize=14, fontweight='bold')\n",
    "plt.suptitle((\"SI,CH and DBI scores for WGCNA and ScC-WGCNA clustering on sample data\"), fontsize=20, fontweight='bold')\n",
    "fig = plt.gcf()\n",
    "#fig.savefig(outdir+\"SI,CH and DBI scores for WGCNA, ScC-WGCNA and KMeans clustering on sample data.png\", dpi=1080)#\n",
    "fig.savefig(outdir+distance+\".SI,CH and DBI scores for WGCNA and ScC-WGCNA clustering on sample data.png\", bbox_inches='tight', dpi=1080)\n",
    "fig.savefig(outdir+distance+\".SI,CH and DBI scores for WGCNA and ScC-WGCNA clustering on sample data.pdf\", bbox_inches='tight', dpi=100)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#保存各数据集上最大模块密度\n",
    "with open(outdir+distance+\".max_density.txt\", \"w\") as OUT:\n",
    "    for temp in max_density:\n",
    "        OUT.write(str(temp) + \"\\t\")\n",
    "    OUT.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73a6ff1-1db7-443b-bf44-c8562934716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#画wgcna的基因数量图、模块平均连通性图和模块密度图\n",
    "\n",
    "labelsdir = \"E:/Project/Project001 WGCNA/main/step-4-wgcna/outdir/\"\n",
    "data_dir = \"E:/Project/Project001 WGCNA/main/step-7-clustering/semi_supervised Kmeans/outdir_updown/pearson/\"\n",
    "outdir = \"E:/Project/Project001 WGCNA/main/step-7-clustering/semi_supervised Kmeans/outdir_updown/wgcna/\"\n",
    "\n",
    "cancer_names = [\"BLCA\", \"BRCA\", \"COAD\", \"KIRC\", \"LUAD\", \"LUSC\", \"STAD\",  \"PAAD\"]#\n",
    "\n",
    "# score_wgcna = dict(SI = [], CH = [], DBI = [])\n",
    "# score_pckmeans = dict(SI = [], CH = [], DBI = [])\n",
    "# #score_kmeans = dict(SI = [], CH = [], DBI = [])\n",
    "# distance = \"pearson\" #\"dcorr\" #\n",
    "# datdir = data_dir+distance+\"/\"\n",
    "\n",
    "max_density = []\n",
    "fig = plt.figure(figsize=(6, 6), dpi=100)# 创建画布, 并设置分辨率为 80像素/每英寸\n",
    "for prefix in cancer_names:\n",
    "    #prefix = \"OV\"\n",
    "    prefix = prefix\n",
    "    print(\"###==================== %s ====================###\\n\" % prefix)\n",
    "\n",
    "    if not os.path.exists(outdir+prefix):\n",
    "        os.makedirs(outdir+prefix)\n",
    "\n",
    "    wgcna_y_pred = pd.read_csv(labelsdir+prefix+\"/\"+prefix+\".wgcna.result.csv\", index_col=False)#KIRC.wgcna.result\n",
    "    wgcna_labels = wgcna_y_pred[\"dynamicMods\"].values\n",
    "    print(\"value_counts:\\n\", pd.DataFrame(pd.value_counts(wgcna_labels)).T)\n",
    "    n_clusters_ =len(np.unique(wgcna_labels)) - (1 if -1 in wgcna_labels else 0) \n",
    "    labels_counts = pd.DataFrame(pd.value_counts(wgcna_labels))\n",
    "    labels_counts.insert(0, \"clusters\", labels_counts.index)\n",
    "    labels_counts.columns = [\"clusters\", \"counts\"]\n",
    "\n",
    "    ADJ = pd.read_csv(datdir+prefix+\"/\"+prefix+\".\"+distance+\".ADJ.csv\", sep=',')\n",
    "    ADJ.index = ADJ.columns\n",
    "    #计算邻接性\n",
    "    Connectivity = ADJ.values\n",
    "    row, col = np.diag_indices_from(Connectivity)\n",
    "    Connectivity[row, col] = 0\n",
    "    Connectivity = pd.DataFrame(Connectivity)\n",
    "\n",
    "\n",
    "    #每个模块的基因数条形图\n",
    "    width = 0.35# 柱子的宽度\n",
    "    #fig = plt.figure(figsize=(6, 6), dpi=80)# 创建画布, 并设置分辨率为 80像素/每英寸\n",
    "    plt.clf() # 使用 plt.clf() 清理掉 axes\n",
    "    plt.subplot(111)# 创建一个子图\n",
    "    #plt.title(\"Number of genes in the module\", fontsize=18)\n",
    "    plt.xlabel(\"Module\", fontsize=16)\n",
    "    plt.ylabel(\"Number of genes\", fontsize=16)\n",
    "    plt.bar(labels_counts.loc[:, \"clusters\"], labels_counts.loc[:, \"counts\"], width, color=\"#87CEFA\") # 绘制柱状图, 每根柱子的颜色为紫罗兰色\n",
    "    fig.savefig(outdir+prefix+\"/\"+prefix+\".wgcna.Number of genes in the module.png\", dpi=1080, bbox_inches='tight')  \n",
    "\n",
    "\n",
    "\n",
    "    #模块内平均连通性\n",
    "    values = []\n",
    "    for k in np.sort(np.unique(wgcna_labels)):      \n",
    "        values.append(sum(Connectivity.loc[wgcna_labels==k, wgcna_labels==k].sum())/sum(wgcna_labels==k))\n",
    "    width = 0.35# 柱子的宽度\n",
    "    #fig = plt.figure(figsize=(6, 6), dpi=80)# 创建画布, 并设置分辨率为 80像素/每英寸\n",
    "    plt.clf() # 使用 plt.clf() 清理掉 axes\n",
    "    plt.subplot(111)# 创建一个子图\n",
    "    plt.title(\"Mean Connectivity of module\", fontsize=18)\n",
    "    plt.xlabel(\"Module\", fontsize=16)\n",
    "    plt.ylabel(\"Mean Connectivity\", fontsize=16)\n",
    "    plt.bar(np.sort(np.unique(wgcna_labels)), values, width, color=\"#87CEFA\") # 绘制柱状图, 每根柱子的颜色为紫罗兰色ind-width/2\n",
    "    fig.savefig(outdir+prefix+\"/\"+prefix+\".wgcna.Mean_Connectivity_of_module.png\", dpi=1080, bbox_inches='tight')\n",
    "\n",
    "\n",
    "    #模块密度\n",
    "    values = []\n",
    "    for k in np.sort(np.unique(wgcna_labels)):      \n",
    "        values.append(sum(Connectivity.loc[wgcna_labels==k, wgcna_labels==k].sum())/(sum(wgcna_labels==k)*(sum(wgcna_labels==k)-1)))\n",
    "    max_density.append(max(values))\n",
    "    width = 0.35# 柱子的宽度\n",
    "    #fig = plt.figure(figsize=(6, 6), dpi=80)# 创建画布, 并设置分辨率为 80像素/每英寸\n",
    "    plt.clf() # 使用 plt.clf() 清理掉 axes\n",
    "    plt.subplot(111)# 创建一个子图\n",
    "    #plt.title(\"Density of module\", fontsize=18)\n",
    "    plt.xlabel(\"Module\", fontsize=16)\n",
    "    plt.ylabel(\"Density of module\", fontsize=16)\n",
    "    plt.bar(np.sort(np.unique(wgcna_labels)), values, width, color=\"#87CEFA\") # 绘制柱状图, 每根柱子的颜色为紫罗兰色ind-width/2\n",
    "    fig.savefig(outdir+prefix+\"/\"+prefix+\".wgcna.density_of_module.png\", dpi=1080, bbox_inches='tight')\n",
    "\n",
    "#保存各数据集上最大模块密度\n",
    "with open(outdir+\"wgcna.max_density.txt\", \"w\") as OUT:\n",
    "    for temp in max_density:\n",
    "        OUT.write(str(temp) + \"\\t\")\n",
    "    OUT.write(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
