{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff08c965-ad0a-4b57-9957-0bebb872f587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os, re, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity, calculate_kmo  # 载入两个检验\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "workdir = \"./\"\n",
    "filename = '.tcga_gtex.tpm.updown.feature_selection.csv'\n",
    "outdir = \"./outdir/factor analyzer\"\n",
    "datDir = \"./outdir/feature selection\"\n",
    "pathwayDir = \"./outdir/enrichment analysis\"\n",
    "prefix = \"BLCA\"\n",
    "\n",
    "outdir1 = '/'.join([outdir, 'pathway profile'])\n",
    "outdir2 = '/'.join([outdir, 'factor analyzer'])\n",
    "\n",
    "if not os.path.exists(outdir1):\n",
    "    os.makedirs(outdir1)\n",
    "if not os.path.exists(outdir2):\n",
    "    os.makedirs(outdir2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e9c8f8-64b1-445d-9f5d-0fed2dc1df48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(datDir, prefix, prefix+filename), sep=',', index_col=0)\n",
    "with open(os.path.join(pathwayDir, prefix, \"GO\", prefix+\".GO_BP.txt\"), \"r\") as fd:\n",
    "    fd.readline()\n",
    "    for pathway in fd:\n",
    "        Item = pathway.split(\"\\t\")\n",
    "        pathwayID = Item[0]\n",
    "        pathwayID = pathwayID.replace(':', '_')\n",
    "        geneID = Item[7]\n",
    "        genes = geneID.split(\"/\")\n",
    "        if len(genes)!=int(Item[8].replace('\\n', '')):\n",
    "            print(\"Gene number wrong!\")\n",
    "        pathwayEM = df.loc[df.index.isin(genes)]\n",
    "        pathwayEM.insert(loc=0, column='SYMBOL', value=pathwayEM.index)\n",
    "        if not os.path.exists(os.path.join(outdir1, prefix)):\n",
    "            os.makedirs(os.path.join(outdir1, prefix))\n",
    "        pathwayEM.to_csv(os.path.join(outdir1, prefix, prefix+filename.rstrip(\"csv\")+pathwayID+\".csv\"), header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da01a89-0d37-4e9f-8c01-ab8ea8dc0d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_count = {}\n",
    "ml_ratio = {}\n",
    "savefig = False\n",
    "\n",
    "t1 = time.time()\n",
    "print(prefix + \"========>\\tStart factor analysis...\")\n",
    "\n",
    "df = pd.read_csv(os.path.join(datDir, prefix, prefix + filename), sep=',', index_col=0)\n",
    "\n",
    "file_list = os.listdir(os.path.join(outdir1, prefix))\n",
    "file_list = list(filter(lambda x: prefix + filename.rstrip(\".csv\")+'.GO_' in str(x), file_list))  # 只取包含' '的字符串\n",
    "print(\"GO counts:%d\" % len(file_list))\n",
    "\n",
    "if not os.path.exists(os.path.join(outdir2, prefix)):\n",
    "    os.makedirs(os.path.join(outdir2, prefix))\n",
    "\n",
    "factor_analyzer_test = {}\n",
    "factor_analyzer_test[\"ID\"] = []\n",
    "factor_analyzer_test[\"chi_square_value\"] = []\n",
    "factor_analyzer_test[\"chi_square_p_value\"] = []\n",
    "factor_analyzer_test[\"kmo_total\"] = []\n",
    "factor_analyzer_test[\"test\"] = []\n",
    "count = 0\n",
    "\n",
    "cluster_ml = []\n",
    "cluster_ml.append(df.index.values)\n",
    "cluster_seed = []\n",
    "cluster_seed.append(df.index.values)\n",
    "\n",
    "for i in range(len(file_list)):\n",
    "    pathway_id = re.search(\"(\\.GO.*)\\.\", file_list[i], flags=0).group(0)\n",
    "    df = pd.read_csv(os.path.join(outdir1, prefix, file_list[i]))\n",
    "    count = count + 1\n",
    "    if df.shape[0] < 5:\n",
    "        factor_analyzer_test[\"ID\"].append(file_list[i].split('.')[4])\n",
    "        factor_analyzer_test[\"chi_square_value\"].append(\"NaN\")\n",
    "        factor_analyzer_test[\"chi_square_p_value\"].append(\"NaN\")\n",
    "        factor_analyzer_test[\"kmo_total\"].append(\"NaN\")\n",
    "        factor_analyzer_test[\"test\"].append(\"Genes count is less than 5\")\n",
    "        continue\n",
    "    else:\n",
    "        factor_analyzer_test[\"ID\"].append(file_list[i].split('.')[4])\n",
    "\n",
    "    df.index = df['SYMBOL'].values\n",
    "    genelist = df['SYMBOL'].values\n",
    "    df.drop('SYMBOL', axis=1, inplace=True)\n",
    "\n",
    "    if df.isnull().values.ravel().sum():\n",
    "        df.dropna(how=\"all\", axis=0, inplace=True)\n",
    "        df.dropna(how=\"all\", axis=1, inplace=True)\n",
    "        index = df.index\n",
    "        columns = df.columns\n",
    "        imp_mode = SimpleImputer(strategy=\"most_frequent\")\n",
    "        df = imp_mode.fit_transform(df)\n",
    "        df = pd.DataFrame(df, index=index, columns=columns)\n",
    "    # df.dropna(how=\"any\", axis=0, inplace=True)\n",
    "\n",
    "    genelist = df.index\n",
    "    df = df.T\n",
    "    corr_df = df.corr()\n",
    "    corr_df.head()\n",
    "\n",
    "    chi_square_value, p_value = calculate_bartlett_sphericity(df)\n",
    "    factor_analyzer_test[\"chi_square_value\"].append(chi_square_value)\n",
    "    factor_analyzer_test[\"chi_square_p_value\"].append(p_value)\n",
    "    # print('chi_square_value: %.4f \\n kmo_total: %.4f\\n' % (chi_square_value, p_value))\n",
    "\n",
    "    kmo_per_variable, kmo_total = calculate_kmo(df)\n",
    "    factor_analyzer_test[\"kmo_total\"].append(kmo_total)\n",
    "    # print('kmo_total: %.4f\\n' % (kmo_total))\n",
    "\n",
    "    if kmo_total > 0.6 and p_value < 0.05:\n",
    "        factor_analyzer_test[\"test\"].append(\"Passes two tests\")\n",
    "\n",
    "        if df.shape[1] < 10:\n",
    "            k_factor = df.shape[1]\n",
    "        else:\n",
    "            k_factor = 10\n",
    "        fa = FactorAnalyzer(k_factor, rotation=None)\n",
    "        try:\n",
    "            fa.fit(df)\n",
    "        except:\n",
    "            print(file_list[i])\n",
    "            continue\n",
    "\n",
    "        eig_value, eig_vector = fa.get_eigenvalues()\n",
    "\n",
    "        cum_eig_df = pd.DataFrame()\n",
    "        cum_eig_df['factors'] = pd.Series(range(1, len(genelist) + 1))\n",
    "        cum_eig_df['eig_value'] = eig_value\n",
    "        cum_eig_df['cum_eig_value_ratio'] = np.cumsum(eig_value) / np.sum(eig_value)\n",
    "        \n",
    "        FactorAmount = cum_eig_df[cum_eig_df['cum_eig_value_ratio'] > 0.85].index.min() + 1\n",
    "\n",
    "        rotation_fa = FactorAnalyzer(FactorAmount, method='principal', rotation='varimax')\n",
    "        rotation_fa.fit(df)\n",
    "\n",
    "        rota_factor_df = pd.DataFrame(np.abs(rotation_fa.loadings_), index=genelist)\n",
    "        \n",
    "        # rota_factor_df.sort_values(by=[0, 1, 2], axis=0, ascending=[False, False, False], inplace=True)\n",
    "        # rota_factor_df.sort_values(by=[0], axis=0, ascending=False, inplace=True)\n",
    "\n",
    "        rota_factor_df_bi = copy.deepcopy(rota_factor_df)\n",
    "        \n",
    "        rota_factor_df_bi[rota_factor_df_bi < 0.15] = 0\n",
    "        rota_factor_df_bi[rota_factor_df_bi >= 0.15] = 1\n",
    "        \n",
    "        rota_factor_df_unique = rota_factor_df_bi.loc[rota_factor_df_bi.sum(axis=1) == 1]\n",
    "        \n",
    "        add_flag = False\n",
    "        for n in range(FactorAmount):\n",
    "            cluster = rota_factor_df_unique.index[rota_factor_df_unique[n] == 1].values\n",
    "            if len(cluster) > 1:\n",
    "                add_flag = True\n",
    "                add = 1\n",
    "                for j in range(1, len(cluster_ml)):\n",
    "                    if len(set(cluster)) == len(set(cluster).intersection(set(cluster_ml[j]))):\n",
    "                        add = 0\n",
    "                        break\n",
    "                if add:\n",
    "                    cluster_ml.append(cluster)\n",
    "\n",
    "                add = 0\n",
    "                for k in range(1, len(cluster_seed)):\n",
    "                    if len(set(cluster).intersection(set(cluster_seed[k]))) > 0:\n",
    "                        cluster_seed[k] = list(set(cluster).union(set(cluster_seed[k])))\n",
    "                        add = 1\n",
    "                        break\n",
    "                if not add:\n",
    "                    cluster_seed.append(cluster)\n",
    "        \n",
    "        if add_flag:\n",
    "            corr_df.to_csv(os.path.join(outdir2, prefix, prefix + pathway_id + \"corr.csv\"), index=False)\n",
    "            cum_eig_df.to_csv(os.path.join(outdir2, prefix, prefix + pathway_id + \"FactorAnalyzer.eig_value.csv\"), index=False)\n",
    "            rota_factor_df.to_csv(os.path.join(outdir2, prefix, prefix + pathway_id + \"FactorAnalyzer.rota_factor.csv\"), index=False)\n",
    "            rota_factor_df_bi.to_csv(os.path.join(outdir2, prefix, prefix + pathway_id + \"FactorAnalyzer.rota_factor.bi.csv\"), index=False)\n",
    "            \n",
    "            if savefig:\n",
    "                \n",
    "                plt.clf()\n",
    "                fig = plt.figure(figsize=(20, 8))\n",
    "                plt.style.use({'figure.figsize': (20, 8)})\n",
    "                corr_fig = sns.heatmap(corr_df, cmap='Blues')  # , annot=True\n",
    "                plt.title('Gene Correlation', fontdict={'size': 18})\n",
    "                plt.xlabel('Genes', fontdict={'size': 16})\n",
    "                plt.ylabel('Genes', fontdict={'size': 16})\n",
    "                # fig.set_xticklabels(fig.get_xticklabels(), rotation=-90)\n",
    "                # corr_fig.figure.savefig(os.path.join(outdir2, prefix, prefix + pathway_id + \"corr.png\"),\n",
    "                #                         dpi=1080, x_inches='tight')\n",
    "                corr_fig.figure.savefig(os.path.join(outdir2, prefix, prefix + pathway_id + \"corr.pdf\"))\n",
    "                plt.close()\n",
    "                \n",
    "                plt.clf()\n",
    "                fig = plt.figure(figsize=(20, 8))\n",
    "                plt.scatter(cum_eig_df['factors'], cum_eig_df['eig_value'])\n",
    "                plt.plot(cum_eig_df['factors'], cum_eig_df['eig_value'])\n",
    "                plt.xticks(range(0, cum_eig_df.shape[0]))\n",
    "                plt.yticks(range(0, int(cum_eig_df['eig_value'].max())))\n",
    "                plt.title('Scree Plot', fontdict={'size': 18})\n",
    "                plt.xlabel('Factors', fontdict={'size': 16})\n",
    "                plt.ylabel('Eigenvalue', fontdict={'size': 16})\n",
    "                plt.grid()\n",
    "                eig_value_fig = plt.gcf()\n",
    "                # eig_value_fig.figure.savefig(os.path.join(outdir2, prefix, prefix + pathway_id + \"FactorAnalyzer.eig_value.png\")\n",
    "                #                              , dpi=1080, x_inches='tight')\n",
    "                eig_value_fig.figure.savefig(os.path.join(outdir2, prefix, prefix + pathway_id + \"FactorAnalyzer.eig_value.pdf\"))\n",
    "                plt.close()\n",
    "                \n",
    "                plt.clf()\n",
    "                fig = plt.figure(figsize=(20, 8))\n",
    "                plt.plot(cum_eig_df['factors'], cum_eig_df['cum_eig_value_ratio'])\n",
    "                plt.xticks(range(0, cum_eig_df.shape[0]))\n",
    "                plt.axhline(0.85, ls=\"-\", c=\"red\")\n",
    "                plt.title('Factor Cumulative Contribution Rate', fontdict={'size': 18})\n",
    "                plt.xlabel('Factors', fontdict={'size': 16})\n",
    "                plt.ylabel('Cumulative', fontdict={'size': 16})\n",
    "                plt.grid()\n",
    "                eig_value_ratio_fig = plt.gcf()\n",
    "                # eig_value_ratio_fig.figure.savefig(os.path.join(outdir2, prefix, prefix + pathway_id + \"FactorAnalyzer.eig_value_ratio.png\")\n",
    "                #                                    , dpi=1080, x_inches='tight')\n",
    "                eig_value_ratio_fig.figure.savefig(os.path.join(outdir2, prefix, prefix + pathway_id + \"FactorAnalyzer.eig_value_ratio.pdf\"))\n",
    "                plt.close()\n",
    "                \n",
    "                plt.clf()\n",
    "                fig = plt.figure(figsize=(20, 8))\n",
    "                plt.style.use({'figure.figsize': (20, 8)})\n",
    "                plt.title('Loading Matrix Heatmap', fontdict={'size': 18})\n",
    "                plt.xlabel('Factors', fontdict={'size': 16})\n",
    "                plt.ylabel('Genes', fontdict={'size': 16})\n",
    "                rota_factor_fig = sns.heatmap(rota_factor_df, cmap='Blues')  # , annot=True, center=0\n",
    "                # rota_factor_fig.figure.savefig(os.path.join(outdir2, prefix, prefix + pathway_id + \"FactorAnalyzer.rota_factor.png\")\n",
    "                #                                , dpi=1080, x_inches='tight')\n",
    "                rota_factor_fig.figure.savefig(os.path.join(outdir2, prefix, prefix + pathway_id + \"FactorAnalyzer.rota_factor.pdf\"))\n",
    "                plt.close()\n",
    "                \n",
    "                plt.clf()\n",
    "                fig = plt.figure(figsize=(20, 8))\n",
    "                plt.title('Binarized Loading Matrix Heatmap', fontdict={'size': 18})\n",
    "                plt.xlabel('Factors', fontdict={'size': 16})\n",
    "                plt.ylabel('Genes', fontdict={'size': 16})\n",
    "                fig = sns.heatmap(rota_factor_df_bi, cmap='Blues')  # , annot=True, center=0\n",
    "                # fig.figure.savefig(os.path.join(outdir2, prefix, prefix + pathway_id + \"FactorAnalyzer.rota_factor.bi.png\")\n",
    "                #                    , dpi=1080, x_inches='tight')\n",
    "                fig.figure.savefig(os.path.join(outdir2, prefix, prefix + pathway_id + \"FactorAnalyzer.rota_factor.bi.pdf\"))\n",
    "                plt.close()\n",
    "    \n",
    "    else:\n",
    "        factor_analyzer_test[\"test\"].append(\"Failed both tests\")\n",
    "\n",
    "with open(os.path.join(outdir2, prefix, prefix + \".ml.txt\"), \"w\") as OUT:\n",
    "    for temp in cluster_ml:\n",
    "        for g in temp:\n",
    "            OUT.write(str(g) + \"\\t\")\n",
    "        OUT.write(\"\\n\")\n",
    "\n",
    "with open(os.path.join(outdir2, prefix, prefix + \".ml.union.txt\"), \"w\") as OUT:\n",
    "    for temp in cluster_seed:\n",
    "        for g in temp:\n",
    "            OUT.write(str(g) + \"/\")\n",
    "        OUT.write(str(len(temp)))\n",
    "        OUT.write(\"\\n\")\n",
    "\n",
    "ml_union = []\n",
    "for temp in cluster_seed[1:]:\n",
    "    ml_union = list(set(temp).union(set(ml_union)))\n",
    "ml_count[prefix] = len(ml_union)\n",
    "ml_ratio[prefix] = len(ml_union) / len(cluster_seed[0])\n",
    "print(\"The ratio of constrained genes:\", len(ml_union) / len(cluster_seed[0]))\n",
    "print(\"The number of constrained genes:\", len(ml_union))\n",
    "\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "\n",
    "explode = [0, 0, 0]\n",
    "explode[pd.value_counts(factor_analyzer_test[\"test\"]).index.tolist().index(\"Passes two tests\")] = 0.05\n",
    "\n",
    "sizes_0=[1,0,0,0]\n",
    "patches, l_text, p_text = plt.pie(pd.value_counts(factor_analyzer_test[\"test\"]).values\n",
    "                                  , labels=pd.value_counts(factor_analyzer_test[\"test\"]).index\n",
    "                                  , explode=explode\n",
    "                                  # ,colors=colors\n",
    "                                  , labeldistance=1.1\n",
    "                                  , autopct='%.1f%%'\n",
    "                                  , shadow=False\n",
    "                                  , startangle=90, pctdistance=0.8\n",
    "                                  ,textprops={'fontsize': 14}\n",
    "                                 )\n",
    "plt.pie(sizes_0, radius=0.6, colors='w')#白色内圈\n",
    "plt.axis('equal')\n",
    "for t in l_text:\n",
    "    t.set_size(18)\n",
    "for t in p_text:\n",
    "    t.set_size(18)\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Proportion and %s' % prefix, fontdict={'size': 20})\n",
    "fig = plt.gcf()\n",
    "# fig.savefig(os.path.join(outdir2, prefix, prefix + \".FactorAnalyzer.Pie chart.png\"), dpi=1080, x_inches='tight')\n",
    "fig.savefig(os.path.join(outdir2, prefix, prefix + \".FactorAnalyzer.Pie chart.pdf\"))\n",
    "\n",
    "pd.DataFrame.from_dict(factor_analyzer_test).to_csv(os.path.join(outdir2, prefix, prefix + \".FactorAnalyzer.summary.csv\"), index=True)\n",
    "\n",
    "print(pd.value_counts(factor_analyzer_test[\"test\"]))\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"The time of FactorAnalyzer on %s data is %.5fs\" % (prefix, (t2 - t1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
